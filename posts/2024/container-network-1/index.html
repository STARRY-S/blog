<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>初探容器网络 | STARRY-S' Blog</title>
<meta name=keywords content="Network,Container,Kubernetes"><meta name=description content="稍微折腾一下容器网络相关的东西……"><meta name=author content="STARRY-S"><link rel=canonical href=https://blog.starry-s.moe/posts/2024/container-network-1/><link crossorigin=anonymous href=/assets/css/stylesheet.b00f06743954711b22a4a15ad0b966b18e6a0f7e39cea412e471d345bc6b85ca.css integrity="sha256-sA8GdDlUcRsipKFa0LlmsY5qD345zqQS5HHTRbxrhco=" rel="preload stylesheet" as=style><link rel=icon href=https://blog.starry-s.moe/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=https://blog.starry-s.moe/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://blog.starry-s.moe/favicon-32x32.png><link rel=apple-touch-icon href=https://blog.starry-s.moe/apple-touch-icon.png><link rel=mask-icon href=https://blog.starry-s.moe/apple-touch-icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=zh href=https://blog.starry-s.moe/posts/2024/container-network-1/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://fastly.jsdelivr.net/npm/aplayer/dist/APlayer.min.css><script src=https://fastly.jsdelivr.net/npm/aplayer/dist/APlayer.min.js></script><script src=https://fastly.jsdelivr.net/npm/meting/dist/Meting.min.js></script><script>var meting_api="https://api.injahow.cn/meting/?server=:server&type=:type&id=:id&auth=:auth&r=:r"</script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><meta name=msapplication-TileColor content="#da532c"><meta name=theme-color content="#232323"><meta property="og:url" content="https://blog.starry-s.moe/posts/2024/container-network-1/"><meta property="og:site_name" content="STARRY-S' Blog"><meta property="og:title" content="初探容器网络"><meta property="og:description" content="稍微折腾一下容器网络相关的东西……"><meta property="og:locale" content="zh"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-02-26T19:21:28+08:00"><meta property="article:modified_time" content="2024-02-26T19:21:28+08:00"><meta property="article:tag" content="Network"><meta property="article:tag" content="Container"><meta property="article:tag" content="Kubernetes"><meta property="og:image" content="https://blog.starry-s.moe/avatar.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://blog.starry-s.moe/avatar.png"><meta name=twitter:title content="初探容器网络"><meta name=twitter:description content="稍微折腾一下容器网络相关的东西……"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.starry-s.moe/posts/"},{"@type":"ListItem","position":2,"name":"初探容器网络","item":"https://blog.starry-s.moe/posts/2024/container-network-1/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"初探容器网络","name":"初探容器网络","description":"稍微折腾一下容器网络相关的东西……\n","keywords":["Network","Container","Kubernetes"],"articleBody":"稍微折腾一下容器网络相关的东西……\nLinux 网络命名空间 在熟悉容器网络之前，首先来看一下 Linux 网络命名空间 (Network Namespace) 这个东西。Linux 提供了多个不同种类的 Namespace，可以用 lsns 命令查看。\n$ lsns NS TYPE NPROCS PID USER COMMAND 4026531834 time 2 2251 starry-s -zsh 4026531835 cgroup 2 2251 starry-s -zsh 4026531836 pid 2 2251 starry-s -zsh 4026531837 user 2 2251 starry-s -zsh 4026531838 uts 2 2251 starry-s -zsh 4026531839 ipc 2 2251 starry-s -zsh 4026531840 net 2 2251 starry-s -zsh 4026531841 mnt 2 2251 starry-s -zsh ... 参考 network_namespace manpage，Network Namespace 是 Linux 实现网络资源隔离的功能，不同的 Network Namespace 拥有不同的网卡、ARP、路由表等数据。可以使用 iproute2 工具的 ip 命令对 Linux Network Namespace 执行一系列的操作。\n本篇介绍的指令不会系统产生损坏，但建议在虚拟机或一个用于测试的系统上执行 Network Namespace 相关操作，以便于执行重启等暴力操作。\n开始之前，先安装 net-tools 网络工具包。\n$ sudo pacman -S net-tools 查看设备中已有的 Network Namespace。\n$ ip netns list $ ip netns ls ip netns 命令会列出 /var/run/netns/ 目录下存在的 Network Namespace，如果之前没有使用 ip 命令创建过 netns，以上命令基本不会有输出（除非有别的工具也修改了这个目录）。首先创建两个 Network Namespace。\n$ sudo ip netns add ns0 $ sudo ip netns add ns1 $ sudo ip netns ls ns0 ns1 $ ls /var/run/netns/ ns0 ns1 每个 Network Namespace 拥有不同的网卡、路由表、ARP 表等信息，可以使用 ip -n [NAMESPACE] 对某个 netns 进行操作，或通过 ip netns exec 在不同的 netns 下执行命令。\n$ sudo ip -n ns0 link 1: lo: mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 $ sudo ip netns exec ns0 ip link 1: lo: mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 $ sudo ip netns exec ns0 route Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface $ sudo ip netns exec ns0 arp veth pair 连接 Network Namespace 新建的 netns 只有一个 DOWN 状态的回环接口，没有 ARP 和路由表信息，如果想在不同的 netns 之间通信，需要建立 veth pair（Virtual Cabel），把 netns 连接起来。\n可以使用 ip link add type veth 创建一对 veth pair，注意 veth pair 是成对出现的，可以在创建 veth pair 时指定这对 veth pair 名称。\n首先看一下系统自带的接口信息，默认情况下系统有一个 lo 回环接口和一个 eth0 (被重命名为 enp*s* 的接口)，如果运行了 Docker，还会有一个 docker0 接口。\n$ sudo ip link 1: lo: mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: enp1s0: mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000 link/ether ab:cd:ef:89:8f:f5 brd ff:ff:ff:ff:ff:ff 3: docker0: mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default link/ether 02:42:b7:a9:6a:55 brd ff:ff:ff:ff:ff:ff 创建一对 veth pair 名为 veth0 和 veth1。\n$ sudo ip link add veth0 type veth peer name veth1 $ sudo ip link ...... 4: veth1@veth0: mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 5e:7a:4e:96:b1:df brd ff:ff:ff:ff:ff:ff 5: veth0@veth1: mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 5e:5b:51:12:d0:b6 brd ff:ff:ff:ff:ff:ff 之后使用 ip link set 将这对 veth pair 分配到不同的 netns 中。\n$ sudo ip link set veth0 netns ns0 $ sudo ip link set veth1 netns ns1 $ sudo ip -n ns0 link 1: lo: mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 5: veth0@if4: mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 5e:5b:51:12:d0:b6 brd ff:ff:ff:ff:ff:ff link-netns ns1 $ sudo ip -n ns1 link 1: lo: mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 4: veth1@if5: mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 5e:7a:4e:96:b1:df brd ff:ff:ff:ff:ff:ff link-netns ns0 使用 ip addr add 为 veth pair 接口创建 IP 地址，并使用 ip link set [INTERFACE] up 启动网卡接口。\n$ sudo ip -n ns0 addr add 10.0.0.100/24 dev veth0 $ sudo ip -n ns1 addr add 10.0.0.101/24 dev veth1 $ sudo ip -n ns0 link set veth0 up $ sudo ip -n ns1 link set veth1 up $ sudo ip -n ns0 addr 1: lo: mtu 65536 qdisc noop state DOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 5: veth0@if4: mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 5e:5b:51:12:d0:b6 brd ff:ff:ff:ff:ff:ff link-netns ns1 inet 10.0.0.100/24 scope global veth0 valid_lft forever preferred_lft forever inet6 fe80::5c5b:51ff:fe12:d0b6/64 scope link proto kernel_ll valid_lft forever preferred_lft forever $ sudo ip -n ns1 addr 1: lo: mtu 65536 qdisc noop state DOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 4: veth1@if5: mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 5e:7a:4e:96:b1:df brd ff:ff:ff:ff:ff:ff link-netns ns0 inet 10.0.0.101/24 scope global veth1 valid_lft forever preferred_lft forever inet6 fe80::5c7a:4eff:fe96:b1df/64 scope link proto kernel_ll valid_lft forever preferred_lft forever ip addr add 命令在添加 IP 地址时会自动创建路由表信息。现在两个 netns 之间可通过 veth pair 互相通信。\n$ sudo ip -n ns0 route 10.0.0.0/24 dev veth0 proto kernel scope link src 10.0.0.100 $ sudo ip -n ns1 route 10.0.0.0/24 dev veth1 proto kernel scope link src 10.0.0.101 $ sudo ip netns exec ns0 ping -c 1 10.0.0.101 PING 10.0.0.101 (10.0.0.101) 56(84) bytes of data. 64 bytes from 10.0.0.101: icmp_seq=1 ttl=64 time=0.051 ms --- 10.0.0.101 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.051/0.051/0.051/0.000 ms $ sudo ip netns exec ns1 ping -c 1 10.0.0.100 PING 10.0.0.100 (10.0.0.100) 56(84) bytes of data. 64 bytes from 10.0.0.100: icmp_seq=1 ttl=64 time=0.040 ms --- 10.0.0.100 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 0.040/0.040/0.040/0.000 ms 到这里，ns0 和 ns1 两个 Network Namespace 之间的拓扑图如下。\n使用 bridge 连接多个 Network Namespace veth pair 只能用于两个 netns 之间的通信，如果需要多个 netns 访问到同一个网络中，需要配置桥接网络。\n重启系统（清理掉之前创建的 netns 和 veth pair），之后重新建立 ns0, ns1 和 ns2 三个 Network Namespace。\n$ sudo ip netns add ns0 $ sudo ip netns add ns1 $ sudo ip netns add ns2 使用 ip link add 创建一个桥接接口，并建立三对 veth pair，用于连接 br0 和上述三个 netns。\n$ sudo ip link add br0 type bridge $ sudo ip link add veth0-br type veth peer name veth0 $ sudo ip link add veth1-br type veth peer name veth1 $ sudo ip link add veth2-br type veth peer name veth2 $ ip link ... 4: br0: mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether be:60:00:25:c5:37 brd ff:ff:ff:ff:ff:ff 5: veth0@veth0-br: mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 5e:5b:51:12:d0:b6 brd ff:ff:ff:ff:ff:ff 6: veth0-br@veth0: mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 72:01:3d:42:16:8c brd ff:ff:ff:ff:ff:ff 7: veth1@veth1-br: mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 5e:7a:4e:96:b1:df brd ff:ff:ff:ff:ff:ff 8: veth1-br@veth1: mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 1e:13:96:f1:b6:9d brd ff:ff:ff:ff:ff:ff 9: veth2@veth2-br: mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether 62:13:73:b6:5d:f9 brd ff:ff:ff:ff:ff:ff 10: veth2-br@veth2: mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000 link/ether f2:e6:df:92:de:71 brd ff:ff:ff:ff:ff:ff 把 veth0, veth1, veth2 分别放到 ns0, ns1 和 ns2 三个 Network Namespace 中，并将他们重命名为 eth0。\n$ sudo ip link set dev veth0 netns ns0 $ sudo ip link set dev veth1 netns ns1 $ sudo ip link set dev veth2 netns ns2 $ sudo ip -n ns0 link set dev veth0 name eth0 $ sudo ip -n ns1 link set dev veth1 name eth0 $ sudo ip -n ns2 link set dev veth2 name eth0 并把 veth0-br, veth1-br, veth2-br 分别连接到 br0 桥接网卡中。\n$ sudo ip link set dev veth0-br master br0 $ sudo ip link set dev veth1-br master br0 $ sudo ip link set dev veth2-br master br0 启用所有的网卡接口（为了能 ping 通每个 netns 的 127.0.0.1，将每个 ns 的 lo 回环接口也启动）。\n$ sudo ip link set dev br0 up $ sudo ip link set veth0-br up $ sudo ip link set veth1-br up $ sudo ip link set veth2-br up $ sudo ip -n ns0 link set eth0 up $ sudo ip -n ns1 link set eth0 up $ sudo ip -n ns2 link set eth0 up $ sudo ip -n ns0 link set lo up $ sudo ip -n ns1 link set lo up $ sudo ip -n ns2 link set lo up 为 br0 和 netns 中的 veth 接口 （eth0）添加 IP 地址。\n$ sudo ip addr add 10.1.1.1/24 dev br0 $ sudo ip -n ns0 addr add 10.1.1.10/24 dev eth0 $ sudo ip -n ns1 addr add 10.1.1.11/24 dev eth0 $ sudo ip -n ns2 addr add 10.1.1.12/24 dev eth0 查看一下 br0 和 netns 中的 eth0 接口的 IP 地址。\n$ ip a ... 4: br0: mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether be:60:00:25:c5:37 brd ff:ff:ff:ff:ff:ff inet 10.0.0.1/24 scope global br0 valid_lft forever preferred_lft forever 6: veth0-br@if5: mtu 1500 qdisc noqueue master br0 state UP group default qlen 1000 link/ether 72:01:3d:42:16:8c brd ff:ff:ff:ff:ff:ff link-netns ns0 inet6 fe80::7001:3dff:fe42:168c/64 scope link proto kernel_ll valid_lft forever preferred_lft forever 8: veth1-br@if7: mtu 1500 qdisc noqueue master br0 state UP group default qlen 1000 link/ether 1e:13:96:f1:b6:9d brd ff:ff:ff:ff:ff:ff link-netns ns1 inet6 fe80::1c13:96ff:fef1:b69d/64 scope link proto kernel_ll valid_lft forever preferred_lft forever 10: veth2-br@if9: mtu 1500 qdisc noqueue master br0 state UP group default qlen 1000 link/ether f2:e6:df:92:de:71 brd ff:ff:ff:ff:ff:ff link-netns ns2 inet6 fe80::f0e6:dfff:fe92:de71/64 scope link proto kernel_ll valid_lft forever preferred_lft forever $ sudo ip -n ns0 a 5: eth0@if6: mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 5e:5b:51:12:d0:b6 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 10.1.1.10/24 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::5c5b:51ff:fe12:d0b6/64 scope link proto kernel_ll valid_lft forever preferred_lft forever $ sudo ip -n ns1 a 7: eth0@if8: mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 5e:7a:4e:96:b1:df brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 10.1.1.11/24 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::5c7a:4eff:fe96:b1df/64 scope link proto kernel_ll valid_lft forever preferred_lft forever $ sudo ip -n ns2 a 9: eth0@if10: mtu 1500 qdisc noqueue state UP group default qlen 1000 link/ether 62:13:73:b6:5d:f9 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 10.1.1.12/24 scope global eth0 valid_lft forever preferred_lft forever inet6 fe80::6013:73ff:feb6:5df9/64 scope link proto kernel_ll valid_lft forever preferred_lft forever 此时在主机上可以 ping 通三个 netns 的 IP 地址。\n$ ping -c 1 10.1.1.10 PING 10.1.1.10 (10.1.1.10) 56(84) bytes of data. 64 bytes from 10.1.1.10: icmp_seq=1 ttl=64 time=0.130 ms $ ping -c 1 10.1.1.11 PING 10.1.1.11 (10.1.1.11) 56(84) bytes of data. 64 bytes from 10.1.1.11: icmp_seq=1 ttl=64 time=0.117 ms $ ping -c 1 10.1.1.12 PING 10.1.1.12 (10.1.1.12) 56(84) bytes of data. 64 bytes from 10.1.1.12: icmp_seq=1 ttl=64 time=0.119 ms 三个 netns 也可以访问主机的 IP 地址 10.1.1.1。\n$ sudo ip netns exec ns0 ping -c 1 10.1.1.1 PING 10.1.1.1 (10.1.1.1) 56(84) bytes of data. 64 bytes from 10.1.1.1: icmp_seq=1 ttl=64 time=0.076 ms $ sudo ip netns exec ns1 ping -c 1 10.1.1.1 PING 10.1.1.1 (10.1.1.1) 56(84) bytes of data. 64 bytes from 10.1.1.1: icmp_seq=1 ttl=64 time=0.071 ms $ sudo ip netns exec ns2 ping -c 1 10.1.1.1 PING 10.1.1.1 (10.1.1.1) 56(84) bytes of data. 64 bytes from 10.1.1.1: icmp_seq=1 ttl=64 time=0.072 ms 默认情况下 Linux 会把 bridge 的二层转发（交换机）功能禁用掉，因此不同的 netns 之间仍无法互相访问。\n$ sudo ip netns exec ns0 ping -c 1 -W 5 10.1.1.11 PING 10.1.1.11 (10.1.1.11) 56(84) bytes of data. --- 10.1.1.11 ping statistics --- 1 packets transmitted, 0 received, 100% packet loss, time 0ms 使用 IP 桌子，激活桥接接口的转发功能。\n$ sudo iptables -A FORWARD -i br0 -j ACCEPT 此时不同的 netns 之间可以互相 ping 通了。\n$ sudo ip netns exec ns0 ping 10.1.1.12 PING 10.1.1.12 (10.1.1.12) 56(84) bytes of data. 64 bytes from 10.1.1.12: icmp_seq=1 ttl=64 time=0.148 ms 到这里有关 Linux Network Namespace 的配置就可以完美的告一段落了，咱创建了三个 netns，它们之间可以通过 10.1.1.0/24 这一个网段通过 bridge 桥接网卡和 veth pair 实现互相二层（交换机）访问，此时的网络拓扑图变成了下面这样子。\n如果想要更进一步，要实现 netns 内访问其他网段的 IP 地址，还需要再做一些配置，让主机实现网关功能，并配置 NAT，让主机实现 3 层地址转发（路由器）。\n$ sudo ip netns exec ns0 ping -c 1 8.8.8.8 ping: connect: Network is unreachable 首先需要将主机的网卡（咱这里为 enp1s0，不同系统可能不一样）也添加到将桥接网卡 br0 中，这里要注意把主机的网卡 enp1s0 添加到桥接网卡 br0 后，要把 enp1s0 网卡上的 IP 地址（咱这里为 192.168.122.101/24）改到桥接网卡 br0 上，不然过一段时间后会网络中断。\n这里不要 ssh 远程操作。\n$ sudo ip link set enp1s0 master br0 $ sudo ip addr del 192.168.122.101/24 dev enp1s0 $ sudo ip addr add 192.168.122.101/24 dev br0 手动为 netns 设定默认网关 10.1.1.1/24。\n$ sudo ip -n ns0 route add default via 10.1.1.1 $ sudo ip -n ns1 route add default via 10.1.1.1 $ sudo ip -n ns2 route add default via 10.1.1.1 接下来使用 IP 桌子配置 IP 地址转发，这里的指令和之前配置 Linux 主机做路由器是一样的。\n$ sudo iptables --table nat -A POSTROUTING -s 10.1.1.0/24 -j MASQUERADE 查看一下 netns 中的路由表，这时的默认流量会走 10.1.1.1 网关。\n$ sudo ip -n ns0 route default via 10.1.1.1 dev eth0 10.1.1.0/24 dev eth0 proto kernel scope link src 10.1.1.10 到这里如果不出意外的话，三个 netns 已经具备访问公网的能力了。\n$ sudo ip netns exec ns0 ping -c 1 8.8.8.8 PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data. 64 bytes from 8.8.8.8: icmp_seq=1 ttl=112 time=66.0 ms --- 8.8.8.8 ping statistics --- 1 packets transmitted, 1 received, 0% packet loss, time 0ms rtt min/avg/max/mdev = 65.964/65.964/65.964/0.000 ms 容器网络 其实上面咱演示的使用 bridge 桥接网卡 + veth pair 配置多个 Network Namespace 互相访问的这个网络模型基本上就和 Docker 默认的 bridge 网络模型没啥区别了。\n只是 Docker 使用 runc/libcontainer 没有把容器对应的 Network Namespace 文件放到 /var/run/netns/ 目录，使用 ip netns 命令发现不到它。不过带胶布，可以把 Docker 容器中应用的 Network Namespace 对应文件软链接到 /var/run/netns/ 目录中，再使用 ip 命令执行一些操作。\n首先跑一个 nginx 容器，使用 docker inspect 获取进程的 PID。\n$ docker run -dit --name nginx -p 80:80 nginx $ docker inspect --format '{{.State.Pid}}' nginx 993 创建软链接，将进程的 netns 文件链接到 /var/run/netns 目录。\n$ sudo mkdir -p /var/run/netns $ sudo ln -s /proc/993/ns/net /var/run/netns/ns-993 $ ip netns ns-993 $ sudo ip netns exec ns-993 ip addr 1: lo: mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 4: eth0@if5: mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever 之后可以像上面那样，再建立一对 veth pair，为容器创建 “第二个网卡” eth1，实现主机和容器之间的访问。\n$ sudo ip link add eth0-ns-993 type veth peer name veth-ns-993 $ sudo ip link set eth0-ns-993 netns ns-993 $ sudo ip -n ns-993 link set dev eth0-ns-993 name eth1 $ sudo ip -n ns-993 addr 1: lo: mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever 4: eth0@if5: mtu 1500 qdisc noqueue state UP group default link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0 inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0 valid_lft forever preferred_lft forever 9: eth1@if8: mtu 1500 qdisc noop state DOWN group default qlen 1000 link/ether 36:57:fa:63:3b:f0 brd ff:ff:ff:ff:ff:ff link-netnsid 0 $ sudo ip addr add 10.1.0.1/24 dev veth-ns-993 $ sudo ip -n ns-993 addr add 10.1.0.2/24 dev eth1 $ sudo ip link set dev veth-ns-993 up $ sudo ip -n ns-993 link set dev eth1 up $ ping 10.1.0.2 PING 10.1.0.2 (10.1.0.2) 56(84) bytes of data. 64 bytes from 10.1.0.2: icmp_seq=1 ttl=64 time=0.040 ms ... $ curl 10.1.0.2 \u003c!DOCTYPE html\u003e Welcome to nginx! ... 看吧，就是这么的简单（确信）。\n所以在运行了 Docker 的主机上执行 ip 命令有时能看到一大堆 veth 开头的网卡设备名，到这里我们就能明白这些实际上是 veth pair，一端连接到了 docker0 桥接网卡上，另一端则连接在 Docker 容器的 Network Namespace 中。\n$ ip l 3: docker0: mtu 1500 qdisc noqueue state UP mode DEFAULT group default link/ether 02:42:48:1b:aa:e0 brd ff:ff:ff:ff:ff:ff 5: veth077b91e@if4: mtu 1500 qdisc noqueue master docker0 state UP mode DEFAULT group default link/ether 6e:29:0d:fb:d2:43 brd ff:ff:ff:ff:ff:ff link-netnsid 0 Kubernetes Pod 众所周知，Kubernetes 的一个 Pod 中可以包含多个容器，这些容器共用一个网络命名空间，不同容器运行的程序可以直接通过 127.0.0.1 回环地址互相访问。这里需要补充一个萌新容易混淆的概念就是，Linux 的 Namespace 和 Kubernetes 的 Namespace 不是一个东西，前者是 Linux 内核 Level 的特性，后者是 Kubernetes API Server Level 的功能，虽然都叫 Namespace 但他俩不是一个东西。\n那么 Kubernetes 的 Pod 是如何实现多个容器共用一个 Network Namespace 的呢？之前用过 Kubernetes 的小朋友可能会注意到他们的 Container Runtime 中总能看到名叫 pause 的容器，这又是干什么的呢？\nDocker 的网络模型除了默认的 bridge 之外，还有 host, none 和 container 这几种。其中 host 是指和主机共用同一个网络命名空间，none 是容器的 Network Namespace 不配置任何额外的网络。而 container 网络模型则是用来指定一个已有的容器，和他共用同一个 Network Namespace。\nKubernetes 的 Pod 需要让多个容器共用同一个 Network Namespace，所以需要先找一个容器创建 Network Namespace，再让其他容器加入到这个预先创建好的 Network Namespace 中。让 Pod 中任何一个容器作为创建 Network Namespace 的容器都不合适，所以就出来了一个 pause 容器，这个容器体积很小，运行之后其进程永远处于休眠（pause）状态，且 pause 容器的进程 PID 为 1，因为除了创建网络命名空间外，pause 容器还创建了 Linux 进程命名空间，用于回收僵尸进程。\nPause 容器的源码可以在 这里 找到，可以看到它主要确保自己的 PID 为 1，处理一些 Linux Signal 之外，其余时间一直都在 pause。\n可以用 Docker 的 container 网络模型模拟一个 Kubernetes 的 Pod，因为想不出什么太合适的栗子，所以这个 “Pod” 里运行了一个 nginx server 和一个 registry server。\n$ docker run -d --name pause -p 8080:80 -p 5000:5000 --ipc=shareable rancher/mirrored-pause:3.6 $ docker run -d --name nginx --net=container:pause --ipc=container:pause --pid=container:pause nginx $ docker run -d --name registry --net=container:pause --ipc=container:pause --pid=container:pause registry $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES eaace8974956 registry \"/entrypoint.sh /etc…\" 2 minutes ago Up 2 minutes registry 247ed1ca07e3 nginx \"/docker-entrypoint.…\" 2 minutes ago Up 2 minutes nginx 6cdf835a09f0 rancher/mirrored-pause:3.6 \"/pause\" 2 minutes ago Up 2 minutes 0.0.0.0:5000-\u003e5000/tcp, :::5000-\u003e5000/tcp, 0.0.0.0:8080-\u003e80/tcp, :::8080-\u003e80/tcp pause $ curl 127.0.0.1:8080 \u003c!DOCTYPE html\u003e Welcome to nginx! ... $ docker login 127.0.0.1:5000 Username: admin Password: Login Succeeded ","wordCount":"4586","inLanguage":"zh","image":"https://blog.starry-s.moe/avatar.png","datePublished":"2024-02-26T19:21:28+08:00","dateModified":"2024-02-26T19:21:28+08:00","author":{"@type":"Person","name":"STARRY-S"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.starry-s.moe/posts/2024/container-network-1/"},"publisher":{"@type":"Organization","name":"STARRY-S' Blog","logo":{"@type":"ImageObject","url":"https://blog.starry-s.moe/favicon-32x32.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://blog.starry-s.moe/ accesskey=h title="Blog (Alt + H)"><img src=https://blog.starry-s.moe/apple-touch-icon.png alt aria-label=logo height=24>Blog</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://blog.starry-s.moe/gallery/ title=相册><span>相册</span></a></li><li><a href=https://blog.starry-s.moe/archives/ title=归档><span>归档</span></a></li><li><a href=https://blog.starry-s.moe/tags/ title=标签><span>标签</span></a></li><li><a href=https://blog.starry-s.moe/categories/ title=分类><span>分类</span></a></li><li><a href=https://blog.starry-s.moe/search/ title="搜索 (Alt + /)" accesskey=/><span>搜索</span></a></li><li><a href=https://blog.starry-s.moe/projects/ title=项目><span>项目</span></a></li><li><a href=https://blog.starry-s.moe/about/ title=关于><span>关于</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://blog.starry-s.moe/>主页</a>&nbsp;»&nbsp;<a href=https://blog.starry-s.moe/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">初探容器网络</h1><div class=post-meta><span title='2024-02-26 19:21:28 +0800 +0800'>2024-02-26 19:21:28 +0800</span>&nbsp;·&nbsp;10 分钟&nbsp;·&nbsp;4586 字&nbsp;·&nbsp;STARRY-S&nbsp;|&nbsp;<a href=https://github.com/STARRY-S/blog/edit/main/content/posts/2024/container-network-1/index.md rel="noopener noreferrer" target=_blank>Edit Text</a></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>目录</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#linux-网络命名空间>Linux 网络命名空间</a><ul><li><a href=#veth-pair-连接-network-namespace>veth pair 连接 Network Namespace</a></li><li><a href=#使用-bridge-连接多个-network-namespace>使用 bridge 连接多个 Network Namespace</a></li></ul></li><li><a href=#容器网络>容器网络</a></li><li><a href=#kubernetes-pod>Kubernetes Pod</a></li></ul></nav></div></details></div><div class=post-content><p>稍微折腾一下容器网络相关的东西……</p><meting-js server=netease type=song id=1388992194 theme=#233333></meting-js><h2 id=linux-网络命名空间>Linux 网络命名空间<a hidden class=anchor aria-hidden=true href=#linux-网络命名空间>#</a></h2><p>在熟悉容器网络之前，首先来看一下 Linux 网络命名空间 (Network Namespace) 这个东西。Linux 提供了多个不同种类的 Namespace，可以用 <code>lsns</code> 命令查看。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> lsns
</span></span><span class=line><span class=cl><span class=go>        NS TYPE   NPROCS   PID USER     COMMAND
</span></span></span><span class=line><span class=cl><span class=go>4026531834 time        2  2251 starry-s -zsh
</span></span></span><span class=line><span class=cl><span class=go>4026531835 cgroup      2  2251 starry-s -zsh
</span></span></span><span class=line><span class=cl><span class=go>4026531836 pid         2  2251 starry-s -zsh
</span></span></span><span class=line><span class=cl><span class=go>4026531837 user        2  2251 starry-s -zsh
</span></span></span><span class=line><span class=cl><span class=go>4026531838 uts         2  2251 starry-s -zsh
</span></span></span><span class=line><span class=cl><span class=go>4026531839 ipc         2  2251 starry-s -zsh
</span></span></span><span class=line><span class=cl><span class=go>4026531840 net         2  2251 starry-s -zsh
</span></span></span><span class=line><span class=cl><span class=go>4026531841 mnt         2  2251 starry-s -zsh
</span></span></span><span class=line><span class=cl><span class=go>...
</span></span></span></code></pre></div><p>参考 <a href=https://man7.org/linux/man-pages/man7/network_namespaces.7.html>network_namespace manpage</a>，Network Namespace 是 Linux 实现网络资源隔离的功能，不同的 Network Namespace 拥有不同的网卡、ARP、路由表等数据。可以使用 <code>iproute2</code> 工具的 <code>ip</code> 命令对 Linux Network Namespace 执行一系列的操作。</p><blockquote><p>本篇介绍的指令不会系统产生损坏，但建议在虚拟机或一个用于测试的系统上执行 Network Namespace 相关操作，以便于执行重启等暴力操作。</p></blockquote><p>开始之前，先安装 <code>net-tools</code> 网络工具包。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo pacman -S net-tools
</span></span></code></pre></div><p>查看设备中已有的 Network Namespace。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> ip netns list
</span></span><span class=line><span class=cl><span class=gp>$</span> ip netns ls
</span></span></code></pre></div><p><code>ip netns</code> 命令会列出 <code>/var/run/netns/</code> 目录下存在的 Network Namespace，如果之前没有使用 <code>ip</code> 命令创建过 netns，以上命令基本不会有输出（除非有别的工具也修改了这个目录）。首先创建两个 Network Namespace。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip netns add ns0
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip netns add ns1
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip netns ls
</span></span><span class=line><span class=cl><span class=go>ns0
</span></span></span><span class=line><span class=cl><span class=go>ns1
</span></span></span><span class=line><span class=cl><span class=go></span><span class=gp>$</span> ls /var/run/netns/
</span></span><span class=line><span class=cl><span class=go>ns0 ns1
</span></span></span></code></pre></div><p>每个 Network Namespace 拥有不同的网卡、路由表、ARP 表等信息，可以使用 <code>ip -n [NAMESPACE]</code> 对某个 netns 进行操作，或通过 <code>ip netns exec</code> 在不同的 netns 下执行命令。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns0 link
</span></span><span class=line><span class=cl><span class=go>1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class=line><span class=cl><span class=go></span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=gp>$</span> sudo ip netns <span class=nb>exec</span> ns0 ip link
</span></span><span class=line><span class=cl><span class=go>1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class=line><span class=cl><span class=go></span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=gp>$</span> sudo ip netns <span class=nb>exec</span> ns0 route
</span></span><span class=line><span class=cl><span class=go>Kernel IP routing table
</span></span></span><span class=line><span class=cl><span class=go>Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
</span></span></span><span class=line><span class=cl><span class=go></span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=gp>$</span> sudo ip netns <span class=nb>exec</span> ns0 arp
</span></span></code></pre></div><h3 id=veth-pair-连接-network-namespace>veth pair 连接 Network Namespace<a hidden class=anchor aria-hidden=true href=#veth-pair-连接-network-namespace>#</a></h3><p>新建的 netns 只有一个 DOWN 状态的回环接口，没有 ARP 和路由表信息，如果想在不同的 netns 之间通信，需要建立 veth pair（Virtual Cabel），把 netns 连接起来。</p><p>可以使用 <code>ip link add type veth</code> 创建一对 veth pair，注意 veth pair 是成对出现的，可以在创建 veth pair 时指定这对 veth pair 名称。</p><p>首先看一下系统自带的接口信息，默认情况下系统有一个 <code>lo</code> 回环接口和一个 <code>eth0</code> (被重命名为 <code>enp*s*</code> 的接口)，如果运行了 Docker，还会有一个 <code>docker0</code> 接口。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip link
</span></span><span class=line><span class=cl><span class=go>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class=line><span class=cl><span class=go>2: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether ab:cd:ef:89:8f:f5 brd ff:ff:ff:ff:ff:ff
</span></span></span><span class=line><span class=cl><span class=go>3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default 
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 02:42:b7:a9:6a:55 brd ff:ff:ff:ff:ff:ff
</span></span></span></code></pre></div><p>创建一对 veth pair 名为 <code>veth0</code> 和 <code>veth1</code>。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip link add veth0 <span class=nb>type</span> veth peer name veth1
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip link
</span></span><span class=line><span class=cl><span class=go>......
</span></span></span><span class=line><span class=cl><span class=go>4: veth1@veth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 5e:7a:4e:96:b1:df brd ff:ff:ff:ff:ff:ff
</span></span></span><span class=line><span class=cl><span class=go>5: veth0@veth1: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 5e:5b:51:12:d0:b6 brd ff:ff:ff:ff:ff:ff
</span></span></span></code></pre></div><p>之后使用 <code>ip link set</code> 将这对 veth pair 分配到不同的 netns 中。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip link <span class=nb>set</span> veth0 netns ns0
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip link <span class=nb>set</span> veth1 netns ns1
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns0 link
</span></span><span class=line><span class=cl><span class=go>1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class=line><span class=cl><span class=go>5: veth0@if4: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 5e:5b:51:12:d0:b6 brd ff:ff:ff:ff:ff:ff link-netns ns1
</span></span></span><span class=line><span class=cl><span class=go></span><span class=gp>$</span> sudo ip -n ns1 link
</span></span><span class=line><span class=cl><span class=go>1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class=line><span class=cl><span class=go>4: veth1@if5: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 5e:7a:4e:96:b1:df brd ff:ff:ff:ff:ff:ff link-netns ns0
</span></span></span></code></pre></div><p>使用 <code>ip addr add</code> 为 veth pair 接口创建 IP 地址，并使用 <code>ip link set [INTERFACE] up</code> 启动网卡接口。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns0 addr add 10.0.0.100/24 dev veth0
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns1 addr add 10.0.0.101/24 dev veth1
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns0 link <span class=nb>set</span> veth0 up
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns1 link <span class=nb>set</span> veth1 up
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns0 addr
</span></span><span class=line><span class=cl><span class=go>1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class=line><span class=cl><span class=go>5: veth0@if4: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 5e:5b:51:12:d0:b6 brd ff:ff:ff:ff:ff:ff link-netns ns1
</span></span></span><span class=line><span class=cl><span class=go>    inet 10.0.0.100/24 scope global veth0
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span><span class=line><span class=cl><span class=go>    inet6 fe80::5c5b:51ff:fe12:d0b6/64 scope link proto kernel_ll 
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span><span class=line><span class=cl><span class=go></span><span class=gp>$</span> sudo ip -n ns1 addr
</span></span><span class=line><span class=cl><span class=go>1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class=line><span class=cl><span class=go>4: veth1@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 5e:7a:4e:96:b1:df brd ff:ff:ff:ff:ff:ff link-netns ns0
</span></span></span><span class=line><span class=cl><span class=go>    inet 10.0.0.101/24 scope global veth1
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span><span class=line><span class=cl><span class=go>    inet6 fe80::5c7a:4eff:fe96:b1df/64 scope link proto kernel_ll 
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span></code></pre></div><p><code>ip addr add</code> 命令在添加 IP 地址时会自动创建路由表信息。现在两个 netns 之间可通过 veth pair 互相通信。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns0 route
</span></span><span class=line><span class=cl><span class=go>10.0.0.0/24 dev veth0 proto kernel scope link src 10.0.0.100 
</span></span></span><span class=line><span class=cl><span class=go></span><span class=gp>$</span> sudo ip -n ns1 route
</span></span><span class=line><span class=cl><span class=go>10.0.0.0/24 dev veth1 proto kernel scope link src 10.0.0.101 
</span></span></span><span class=line><span class=cl><span class=go></span><span class=gp>$</span> sudo ip netns <span class=nb>exec</span> ns0 ping -c <span class=m>1</span> 10.0.0.101
</span></span><span class=line><span class=cl><span class=go>PING 10.0.0.101 (10.0.0.101) 56(84) bytes of data.
</span></span></span><span class=line><span class=cl><span class=go>64 bytes from 10.0.0.101: icmp_seq=1 ttl=64 time=0.051 ms
</span></span></span><span class=line><span class=cl><span class=go></span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=go>--- 10.0.0.101 ping statistics ---
</span></span></span><span class=line><span class=cl><span class=go>1 packets transmitted, 1 received, 0% packet loss, time 0ms
</span></span></span><span class=line><span class=cl><span class=go>rtt min/avg/max/mdev = 0.051/0.051/0.051/0.000 ms
</span></span></span><span class=line><span class=cl><span class=go></span><span class=gp>$</span> sudo ip netns <span class=nb>exec</span> ns1 ping -c <span class=m>1</span> 10.0.0.100
</span></span><span class=line><span class=cl><span class=go>PING 10.0.0.100 (10.0.0.100) 56(84) bytes of data.
</span></span></span><span class=line><span class=cl><span class=go>64 bytes from 10.0.0.100: icmp_seq=1 ttl=64 time=0.040 ms
</span></span></span><span class=line><span class=cl><span class=go></span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=go>--- 10.0.0.100 ping statistics ---
</span></span></span><span class=line><span class=cl><span class=go>1 packets transmitted, 1 received, 0% packet loss, time 0ms
</span></span></span><span class=line><span class=cl><span class=go>rtt min/avg/max/mdev = 0.040/0.040/0.040/0.000 ms
</span></span></span></code></pre></div><p>到这里，<code>ns0</code> 和 <code>ns1</code> 两个 Network Namespace 之间的拓扑图如下。</p><p><img loading=lazy src=images/veth.webp alt></p><h3 id=使用-bridge-连接多个-network-namespace>使用 bridge 连接多个 Network Namespace<a hidden class=anchor aria-hidden=true href=#使用-bridge-连接多个-network-namespace>#</a></h3><p>veth pair 只能用于两个 netns 之间的通信，如果需要多个 netns 访问到同一个网络中，需要配置桥接网络。</p><p>重启系统（清理掉之前创建的 netns 和 veth pair），之后重新建立 <code>ns0</code>, <code>ns1</code> 和 <code>ns2</code> 三个 Network Namespace。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip netns add ns0
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip netns add ns1
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip netns add ns2
</span></span></code></pre></div><p>使用 <code>ip link add</code> 创建一个桥接接口，并建立三对 veth pair，用于连接 <code>br0</code> 和上述三个 netns。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip link add br0 <span class=nb>type</span> bridge
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip link add veth0-br <span class=nb>type</span> veth peer name veth0
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip link add veth1-br <span class=nb>type</span> veth peer name veth1
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip link add veth2-br <span class=nb>type</span> veth peer name veth2
</span></span><span class=line><span class=cl><span class=gp>$</span> ip link
</span></span><span class=line><span class=cl><span class=go>...
</span></span></span><span class=line><span class=cl><span class=go>4: br0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether be:60:00:25:c5:37 brd ff:ff:ff:ff:ff:ff
</span></span></span><span class=line><span class=cl><span class=go>5: veth0@veth0-br: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 5e:5b:51:12:d0:b6 brd ff:ff:ff:ff:ff:ff
</span></span></span><span class=line><span class=cl><span class=go>6: veth0-br@veth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 72:01:3d:42:16:8c brd ff:ff:ff:ff:ff:ff
</span></span></span><span class=line><span class=cl><span class=go>7: veth1@veth1-br: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 5e:7a:4e:96:b1:df brd ff:ff:ff:ff:ff:ff
</span></span></span><span class=line><span class=cl><span class=go>8: veth1-br@veth1: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 1e:13:96:f1:b6:9d brd ff:ff:ff:ff:ff:ff
</span></span></span><span class=line><span class=cl><span class=go>9: veth2@veth2-br: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 62:13:73:b6:5d:f9 brd ff:ff:ff:ff:ff:ff
</span></span></span><span class=line><span class=cl><span class=go>10: veth2-br@veth2: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether f2:e6:df:92:de:71 brd ff:ff:ff:ff:ff:ff
</span></span></span></code></pre></div><p>把 <code>veth0</code>, <code>veth1</code>, <code>veth2</code> 分别放到 <code>ns0</code>, <code>ns1</code> 和 <code>ns2</code> 三个 Network Namespace 中，并将他们重命名为 <code>eth0</code>。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip link <span class=nb>set</span> dev veth0 netns ns0
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip link <span class=nb>set</span> dev veth1 netns ns1
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip link <span class=nb>set</span> dev veth2 netns ns2
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns0 link <span class=nb>set</span> dev veth0 name eth0
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns1 link <span class=nb>set</span> dev veth1 name eth0
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns2 link <span class=nb>set</span> dev veth2 name eth0
</span></span></code></pre></div><p>并把 <code>veth0-br</code>, <code>veth1-br</code>, <code>veth2-br</code> 分别连接到 <code>br0</code> 桥接网卡中。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip link <span class=nb>set</span> dev veth0-br master br0
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip link <span class=nb>set</span> dev veth1-br master br0
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip link <span class=nb>set</span> dev veth2-br master br0
</span></span></code></pre></div><p>启用所有的网卡接口（为了能 ping 通每个 netns 的 <code>127.0.0.1</code>，将每个 ns 的 <code>lo</code> 回环接口也启动）。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip link <span class=nb>set</span> dev br0 up
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip link <span class=nb>set</span> veth0-br up
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip link <span class=nb>set</span> veth1-br up
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip link <span class=nb>set</span> veth2-br up
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns0 link <span class=nb>set</span> eth0 up
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns1 link <span class=nb>set</span> eth0 up
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns2 link <span class=nb>set</span> eth0 up
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns0 link <span class=nb>set</span> lo up
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns1 link <span class=nb>set</span> lo up
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns2 link <span class=nb>set</span> lo up
</span></span></code></pre></div><p>为 <code>br0</code> 和 netns 中的 veth 接口 （<code>eth0</code>）添加 IP 地址。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip addr add 10.1.1.1/24 dev br0
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns0 addr add 10.1.1.10/24 dev eth0
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns1 addr add 10.1.1.11/24 dev eth0
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns2 addr add 10.1.1.12/24 dev eth0
</span></span></code></pre></div><p>查看一下 <code>br0</code> 和 netns 中的 <code>eth0</code> 接口的 IP 地址。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> ip a
</span></span><span class=line><span class=cl><span class=go>...
</span></span></span><span class=line><span class=cl><span class=go>4: br0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether be:60:00:25:c5:37 brd ff:ff:ff:ff:ff:ff
</span></span></span><span class=line><span class=cl><span class=go>    inet 10.0.0.1/24 scope global br0
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span><span class=line><span class=cl><span class=go>6: veth0-br@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master br0 state UP group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 72:01:3d:42:16:8c brd ff:ff:ff:ff:ff:ff link-netns ns0
</span></span></span><span class=line><span class=cl><span class=go>    inet6 fe80::7001:3dff:fe42:168c/64 scope link proto kernel_ll 
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span><span class=line><span class=cl><span class=go>8: veth1-br@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master br0 state UP group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 1e:13:96:f1:b6:9d brd ff:ff:ff:ff:ff:ff link-netns ns1
</span></span></span><span class=line><span class=cl><span class=go>    inet6 fe80::1c13:96ff:fef1:b69d/64 scope link proto kernel_ll 
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span><span class=line><span class=cl><span class=go>10: veth2-br@if9: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master br0 state UP group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether f2:e6:df:92:de:71 brd ff:ff:ff:ff:ff:ff link-netns ns2
</span></span></span><span class=line><span class=cl><span class=go>    inet6 fe80::f0e6:dfff:fe92:de71/64 scope link proto kernel_ll 
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span><span class=line><span class=cl><span class=go></span><span class=gp>$</span> sudo ip -n ns0 a
</span></span><span class=line><span class=cl><span class=go>5: eth0@if6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 5e:5b:51:12:d0:b6 brd ff:ff:ff:ff:ff:ff link-netnsid 0
</span></span></span><span class=line><span class=cl><span class=go>    inet 10.1.1.10/24 scope global eth0
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span><span class=line><span class=cl><span class=go>    inet6 fe80::5c5b:51ff:fe12:d0b6/64 scope link proto kernel_ll 
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span><span class=line><span class=cl><span class=go></span><span class=gp>$</span> sudo ip -n ns1 a
</span></span><span class=line><span class=cl><span class=go>7: eth0@if8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 5e:7a:4e:96:b1:df brd ff:ff:ff:ff:ff:ff link-netnsid 0
</span></span></span><span class=line><span class=cl><span class=go>    inet 10.1.1.11/24 scope global eth0
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span><span class=line><span class=cl><span class=go>    inet6 fe80::5c7a:4eff:fe96:b1df/64 scope link proto kernel_ll 
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span><span class=line><span class=cl><span class=go></span><span class=gp>$</span> sudo ip -n ns2 a
</span></span><span class=line><span class=cl><span class=go>9: eth0@if10: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 62:13:73:b6:5d:f9 brd ff:ff:ff:ff:ff:ff link-netnsid 0
</span></span></span><span class=line><span class=cl><span class=go>    inet 10.1.1.12/24 scope global eth0
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span><span class=line><span class=cl><span class=go>    inet6 fe80::6013:73ff:feb6:5df9/64 scope link proto kernel_ll 
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span></code></pre></div><p>此时在主机上可以 ping 通三个 netns 的 IP 地址。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> ping -c <span class=m>1</span> 10.1.1.10
</span></span><span class=line><span class=cl><span class=go>PING 10.1.1.10 (10.1.1.10) 56(84) bytes of data.
</span></span></span><span class=line><span class=cl><span class=go>64 bytes from 10.1.1.10: icmp_seq=1 ttl=64 time=0.130 ms
</span></span></span><span class=line><span class=cl><span class=go></span><span class=gp>$</span> ping -c <span class=m>1</span> 10.1.1.11
</span></span><span class=line><span class=cl><span class=go>PING 10.1.1.11 (10.1.1.11) 56(84) bytes of data.
</span></span></span><span class=line><span class=cl><span class=go>64 bytes from 10.1.1.11: icmp_seq=1 ttl=64 time=0.117 ms
</span></span></span><span class=line><span class=cl><span class=go></span><span class=gp>$</span> ping -c <span class=m>1</span> 10.1.1.12
</span></span><span class=line><span class=cl><span class=go>PING 10.1.1.12 (10.1.1.12) 56(84) bytes of data.
</span></span></span><span class=line><span class=cl><span class=go>64 bytes from 10.1.1.12: icmp_seq=1 ttl=64 time=0.119 ms
</span></span></span></code></pre></div><p>三个 netns 也可以访问主机的 IP 地址 <code>10.1.1.1</code>。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip netns <span class=nb>exec</span> ns0 ping -c <span class=m>1</span> 10.1.1.1
</span></span><span class=line><span class=cl><span class=go>PING 10.1.1.1 (10.1.1.1) 56(84) bytes of data.
</span></span></span><span class=line><span class=cl><span class=go>64 bytes from 10.1.1.1: icmp_seq=1 ttl=64 time=0.076 ms
</span></span></span><span class=line><span class=cl><span class=go></span><span class=gp>$</span> sudo ip netns <span class=nb>exec</span> ns1 ping -c <span class=m>1</span> 10.1.1.1
</span></span><span class=line><span class=cl><span class=go>PING 10.1.1.1 (10.1.1.1) 56(84) bytes of data.
</span></span></span><span class=line><span class=cl><span class=go>64 bytes from 10.1.1.1: icmp_seq=1 ttl=64 time=0.071 ms
</span></span></span><span class=line><span class=cl><span class=go></span><span class=gp>$</span> sudo ip netns <span class=nb>exec</span> ns2 ping -c <span class=m>1</span> 10.1.1.1
</span></span><span class=line><span class=cl><span class=go>PING 10.1.1.1 (10.1.1.1) 56(84) bytes of data.
</span></span></span><span class=line><span class=cl><span class=go>64 bytes from 10.1.1.1: icmp_seq=1 ttl=64 time=0.072 ms
</span></span></span></code></pre></div><p>默认情况下 Linux 会把 bridge 的二层转发（交换机）功能禁用掉，因此不同的 netns 之间仍无法互相访问。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip netns <span class=nb>exec</span> ns0 ping -c <span class=m>1</span> -W <span class=m>5</span> 10.1.1.11
</span></span><span class=line><span class=cl><span class=go>PING 10.1.1.11 (10.1.1.11) 56(84) bytes of data.
</span></span></span><span class=line><span class=cl><span class=go></span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=go>--- 10.1.1.11 ping statistics ---
</span></span></span><span class=line><span class=cl><span class=go>1 packets transmitted, 0 received, 100% packet loss, time 0ms
</span></span></span></code></pre></div><p>使用 IP 桌子，激活桥接接口的转发功能。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo iptables -A FORWARD -i br0 -j ACCEPT
</span></span></code></pre></div><p>此时不同的 netns 之间可以互相 ping 通了。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip netns <span class=nb>exec</span> ns0 ping 10.1.1.12
</span></span><span class=line><span class=cl><span class=go>PING 10.1.1.12 (10.1.1.12) 56(84) bytes of data.
</span></span></span><span class=line><span class=cl><span class=go>64 bytes from 10.1.1.12: icmp_seq=1 ttl=64 time=0.148 ms
</span></span></span></code></pre></div><p>到这里有关 Linux Network Namespace 的配置就可以完美的告一段落了，咱创建了三个 netns，它们之间可以通过 <code>10.1.1.0/24</code> 这一个网段通过 bridge 桥接网卡和 veth pair 实现互相二层（交换机）访问，此时的网络拓扑图变成了下面这样子。</p><p><img loading=lazy src=images/veth-bridge.webp alt></p><hr><p>如果想要更进一步，要实现 netns 内访问其他网段的 IP 地址，还需要再做一些配置，让主机实现网关功能，并配置 NAT，让主机实现 3 层地址转发（路由器）。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip netns <span class=nb>exec</span> ns0 ping -c <span class=m>1</span> 8.8.8.8
</span></span><span class=line><span class=cl><span class=go>ping: connect: Network is unreachable
</span></span></span></code></pre></div><p>首先需要将主机的网卡（咱这里为 <code>enp1s0</code>，不同系统可能不一样）也添加到将桥接网卡 <code>br0</code> 中，这里要注意把主机的网卡 <code>enp1s0</code> 添加到桥接网卡 <code>br0</code> 后，要把 <code>enp1s0</code> 网卡上的 IP 地址（咱这里为 <code>192.168.122.101/24</code>）改到桥接网卡 <code>br0</code> 上，不然过一段时间后会网络中断。</p><blockquote><p>这里<strong>不要</strong> ssh 远程操作。</p></blockquote><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip link <span class=nb>set</span> enp1s0 master br0
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip addr del 192.168.122.101/24 dev enp1s0
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip addr add 192.168.122.101/24 dev br0
</span></span></code></pre></div><p>手动为 netns 设定默认网关 <code>10.1.1.1/24</code>。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns0 route add default via 10.1.1.1
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns1 route add default via 10.1.1.1
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns2 route add default via 10.1.1.1
</span></span></code></pre></div><p>接下来使用 IP 桌子配置 IP 地址转发，这里的指令和之前配置 Linux 主机做路由器是一样的。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo iptables --table nat -A POSTROUTING -s 10.1.1.0/24 -j MASQUERADE
</span></span></code></pre></div><p>查看一下 netns 中的路由表，这时的默认流量会走 <code>10.1.1.1</code> 网关。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns0 route
</span></span><span class=line><span class=cl><span class=go>default via 10.1.1.1 dev eth0 
</span></span></span><span class=line><span class=cl><span class=go>10.1.1.0/24 dev eth0 proto kernel scope link src 10.1.1.10
</span></span></span></code></pre></div><p>到这里如果不出意外的话，三个 netns 已经具备访问公网的能力了。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip netns <span class=nb>exec</span> ns0 ping -c <span class=m>1</span> 8.8.8.8
</span></span><span class=line><span class=cl><span class=go>PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.
</span></span></span><span class=line><span class=cl><span class=go>64 bytes from 8.8.8.8: icmp_seq=1 ttl=112 time=66.0 ms
</span></span></span><span class=line><span class=cl><span class=go></span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=go>--- 8.8.8.8 ping statistics ---
</span></span></span><span class=line><span class=cl><span class=go>1 packets transmitted, 1 received, 0% packet loss, time 0ms
</span></span></span><span class=line><span class=cl><span class=go>rtt min/avg/max/mdev = 65.964/65.964/65.964/0.000 ms
</span></span></span></code></pre></div><h2 id=容器网络>容器网络<a hidden class=anchor aria-hidden=true href=#容器网络>#</a></h2><p>其实上面咱演示的使用 bridge 桥接网卡 + veth pair 配置多个 Network Namespace 互相访问的这个网络模型基本上就和 Docker 默认的 <code>bridge</code> 网络模型没啥区别了。</p><p>只是 Docker 使用 <a href=https://github.com/opencontainers/runc/tree/main/libcontainer>runc/libcontainer</a> 没有把容器对应的 Network Namespace 文件放到 <code>/var/run/netns/</code> 目录，使用 <code>ip netns</code> 命令发现不到它。不过带胶布，可以把 Docker 容器中应用的 Network Namespace 对应文件软链接到 <code>/var/run/netns/</code> 目录中，再使用 <code>ip</code> 命令执行一些操作。</p><p>首先跑一个 <code>nginx</code> 容器，使用 <code>docker inspect</code> 获取进程的 PID。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> docker run -dit --name nginx -p 80:80 nginx
</span></span><span class=line><span class=cl><span class=gp>$</span> docker inspect --format <span class=s1>&#39;{{.State.Pid}}&#39;</span> nginx
</span></span><span class=line><span class=cl><span class=go>993
</span></span></span></code></pre></div><p>创建软链接，将进程的 netns 文件链接到 <code>/var/run/netns</code> 目录。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo mkdir -p /var/run/netns
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ln -s /proc/993/ns/net /var/run/netns/ns-993
</span></span><span class=line><span class=cl><span class=gp>$</span> ip netns
</span></span><span class=line><span class=cl><span class=go>ns-993
</span></span></span><span class=line><span class=cl><span class=go></span><span class=gp>$</span> sudo ip netns <span class=nb>exec</span> ns-993 ip addr
</span></span><span class=line><span class=cl><span class=go>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class=line><span class=cl><span class=go>    inet 127.0.0.1/8 scope host lo
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span><span class=line><span class=cl><span class=go>4: eth0@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default 
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
</span></span></span><span class=line><span class=cl><span class=go>    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span></code></pre></div><p>之后可以像上面那样，再建立一对 veth pair，为容器创建 “第二个网卡” <code>eth1</code>，实现主机和容器之间的访问。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> sudo ip link add eth0-ns-993 <span class=nb>type</span> veth peer name veth-ns-993
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip link <span class=nb>set</span> eth0-ns-993 netns ns-993
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns-993 link <span class=nb>set</span> dev eth0-ns-993 name eth1
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns-993 addr
</span></span><span class=line><span class=cl><span class=go>1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class=line><span class=cl><span class=go>    inet 127.0.0.1/8 scope host lo
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span><span class=line><span class=cl><span class=go>4: eth0@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default 
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
</span></span></span><span class=line><span class=cl><span class=go>    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
</span></span></span><span class=line><span class=cl><span class=go>       valid_lft forever preferred_lft forever
</span></span></span><span class=line><span class=cl><span class=go>9: eth1@if8: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 36:57:fa:63:3b:f0 brd ff:ff:ff:ff:ff:ff link-netnsid 0
</span></span></span><span class=line><span class=cl><span class=go></span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=gp>$</span> sudo ip addr add 10.1.0.1/24 dev veth-ns-993
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns-993 addr add 10.1.0.2/24 dev eth1
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip link <span class=nb>set</span> dev veth-ns-993 up
</span></span><span class=line><span class=cl><span class=gp>$</span> sudo ip -n ns-993 link <span class=nb>set</span> dev eth1 up
</span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=gp>$</span> ping 10.1.0.2
</span></span><span class=line><span class=cl><span class=go>PING 10.1.0.2 (10.1.0.2) 56(84) bytes of data.
</span></span></span><span class=line><span class=cl><span class=go>64 bytes from 10.1.0.2: icmp_seq=1 ttl=64 time=0.040 ms
</span></span></span><span class=line><span class=cl><span class=go>...
</span></span></span><span class=line><span class=cl><span class=go></span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=gp>$</span> curl 10.1.0.2
</span></span><span class=line><span class=cl><span class=go>&lt;!DOCTYPE html&gt;
</span></span></span><span class=line><span class=cl><span class=go>&lt;html&gt;
</span></span></span><span class=line><span class=cl><span class=go>&lt;head&gt;
</span></span></span><span class=line><span class=cl><span class=go>&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</span></span></span><span class=line><span class=cl><span class=go>...
</span></span></span></code></pre></div><p>看吧，就是这么的简单（确信）。</p><p>所以在运行了 Docker 的主机上执行 <code>ip</code> 命令有时能看到一大堆 <code>veth</code> 开头的网卡设备名，到这里我们就能明白这些实际上是 veth pair，一端连接到了 <code>docker0</code> 桥接网卡上，另一端则连接在 Docker 容器的 Network Namespace 中。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> ip l
</span></span><span class=line><span class=cl><span class=go>3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default 
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 02:42:48:1b:aa:e0 brd ff:ff:ff:ff:ff:ff
</span></span></span><span class=line><span class=cl><span class=go>5: veth077b91e@if4: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP mode DEFAULT group default 
</span></span></span><span class=line><span class=cl><span class=go>    link/ether 6e:29:0d:fb:d2:43 brd ff:ff:ff:ff:ff:ff link-netnsid 0
</span></span></span></code></pre></div><h2 id=kubernetes-pod>Kubernetes Pod<a hidden class=anchor aria-hidden=true href=#kubernetes-pod>#</a></h2><p>众所周知，Kubernetes 的一个 Pod 中可以包含多个容器，这些容器共用一个网络命名空间，不同容器运行的程序可以直接通过 <code>127.0.0.1</code> 回环地址互相访问。这里需要补充一个萌新容易混淆的概念就是，Linux 的 Namespace 和 Kubernetes 的 Namespace 不是一个东西，前者是 Linux 内核 Level 的特性，后者是 Kubernetes API Server Level 的功能，虽然都叫 Namespace 但他俩不是一个东西。</p><p>那么 Kubernetes 的 Pod 是如何实现多个容器共用一个 Network Namespace 的呢？之前用过 Kubernetes 的小朋友可能会注意到他们的 Container Runtime 中总能看到名叫 <code>pause</code> 的容器，这又是干什么的呢？</p><p>Docker 的网络模型除了默认的 <code>bridge</code> 之外，还有 <code>host</code>, <code>none</code> 和 <code>container</code> 这几种。其中 <code>host</code> 是指和主机共用同一个网络命名空间，<code>none</code> 是容器的 Network Namespace 不配置任何额外的网络。而 <code>container</code> 网络模型则是用来指定一个已有的容器，和他共用同一个 Network Namespace。</p><p>Kubernetes 的 Pod 需要让多个容器共用同一个 Network Namespace，所以需要先找一个容器创建 Network Namespace，再让其他容器加入到这个预先创建好的 Network Namespace 中。让 Pod 中任何一个容器作为创建 Network Namespace 的容器都不合适，所以就出来了一个 <code>pause</code> 容器，这个容器体积很小，运行之后其进程永远处于休眠（pause）状态，且 pause 容器的进程 PID 为 1，因为除了创建网络命名空间外，<code>pause</code> 容器还创建了 Linux 进程命名空间，用于回收僵尸进程。</p><p>Pause 容器的源码可以在 <a href=https://github.com/kubernetes/kubernetes/blob/master/build/pause/linux/pause.c>这里</a> 找到，可以看到它主要确保自己的 PID 为 1，处理一些 Linux Signal 之外，其余时间一直都在 <code>pause</code>。</p><p>可以用 Docker 的 <code>container</code> 网络模型模拟一个 Kubernetes 的 Pod，因为想不出什么太合适的栗子，所以这个 “Pod” 里运行了一个 nginx server 和一个 registry server。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-console data-lang=console><span class=line><span class=cl><span class=gp>$</span> docker run -d --name pause -p 8080:80 -p 5000:5000 --ipc<span class=o>=</span>shareable rancher/mirrored-pause:3.6
</span></span><span class=line><span class=cl><span class=gp>$</span> docker run -d --name nginx --net<span class=o>=</span>container:pause --ipc<span class=o>=</span>container:pause --pid<span class=o>=</span>container:pause nginx
</span></span><span class=line><span class=cl><span class=gp>$</span> docker run -d --name registry --net<span class=o>=</span>container:pause --ipc<span class=o>=</span>container:pause --pid<span class=o>=</span>container:pause registry
</span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=gp>$</span> docker ps
</span></span><span class=line><span class=cl><span class=go>CONTAINER ID   IMAGE                        COMMAND                  CREATED         STATUS         PORTS                                                                              NAMES
</span></span></span><span class=line><span class=cl><span class=go>eaace8974956   registry                     &#34;/entrypoint.sh /etc…&#34;   2 minutes ago   Up 2 minutes                                                                                      registry
</span></span></span><span class=line><span class=cl><span class=go>247ed1ca07e3   nginx                        &#34;/docker-entrypoint.…&#34;   2 minutes ago   Up 2 minutes                                                                                      nginx
</span></span></span><span class=line><span class=cl><span class=go>6cdf835a09f0   rancher/mirrored-pause:3.6   &#34;/pause&#34;                 2 minutes ago   Up 2 minutes   0.0.0.0:5000-&gt;5000/tcp, :::5000-&gt;5000/tcp, 0.0.0.0:8080-&gt;80/tcp, :::8080-&gt;80/tcp   pause
</span></span></span><span class=line><span class=cl><span class=go></span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=gp>$</span> curl 127.0.0.1:8080
</span></span><span class=line><span class=cl><span class=go>&lt;!DOCTYPE html&gt;
</span></span></span><span class=line><span class=cl><span class=go>&lt;html&gt;
</span></span></span><span class=line><span class=cl><span class=go>&lt;head&gt;
</span></span></span><span class=line><span class=cl><span class=go>&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</span></span></span><span class=line><span class=cl><span class=go>...
</span></span></span><span class=line><span class=cl><span class=go></span><span class=gp>$</span> docker login 127.0.0.1:5000
</span></span><span class=line><span class=cl><span class=go>Username: admin
</span></span></span><span class=line><span class=cl><span class=go>Password: 
</span></span></span><span class=line><span class=cl><span class=go>Login Succeeded
</span></span></span></code></pre></div></div><footer class=post-footer><ul class=post-tags><li><a href=https://blog.starry-s.moe/tags/network/>Network</a></li><li><a href=https://blog.starry-s.moe/tags/container/>Container</a></li><li><a href=https://blog.starry-s.moe/tags/kubernetes/>Kubernetes</a></li></ul><nav class=paginav><a class=prev href=https://blog.starry-s.moe/posts/2024/archlinux-xiaomi-photo-printer-1s/><span class=title>« 上一页</span><br><span>Arch Linux 连接小米照片打印机 1S</span>
</a><a class=next href=https://blog.starry-s.moe/posts/2024/k3s-multus-macvlan/><span class=title>下一页 »</span><br><span>K3s + Multus CNI 插件使用 Macvlan</span></a></nav></footer><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//starry-s-blog.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></article></main><footer class=footer><span>© 2016 - 2025 STARRY-S | <a href=https://creativecommons.org/licenses/by-nc-sa/4.0/>CC BY-NC-SA 4.0</a> | Hosted on <a href=https://pages.github.com>GitHub Pages</a><br></span>·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>const pathname=window.location.pathname,images=document.querySelectorAll("img");Array.from(images).forEach(e=>{if(!pathname.includes("/posts/"))return;if(e.src.indexOf("images")<0)return;e.addEventListener("load",()=>fitImage(e)),e.complete&&e.naturalWidth!==0&&fitImage(e)});function fitImage(e){e.style.marginLeft="auto",e.style.marginRight="auto",e.naturalWidth/e.naturalHeight<1.1&&(e.style.maxWidth="60%",e.style.height="auto")}</script><script src=/js/home-info.js></script><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>