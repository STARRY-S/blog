<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on STARRY-S&#39; Blog</title>
    <link>https://blog.starry-s.moe/posts/</link>
    <description>Recent content in Posts on STARRY-S&#39; Blog</description>
    <image>
      <title>STARRY-S&#39; Blog</title>
      <url>https://blog.starry-s.moe/avatar.png</url>
      <link>https://blog.starry-s.moe/avatar.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <copyright>© 2016 - 2024 STARRY-S | [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/) | Hosted on [GitHub Pages](https://pages.github.com)&lt;br /&gt;</copyright>
    <lastBuildDate>Wed, 12 Jun 2024 23:58:26 +0800</lastBuildDate><atom:link href="https://blog.starry-s.moe/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Leader Election 折腾小记</title>
      <link>https://blog.starry-s.moe/posts/2024/leader-election/</link>
      <pubDate>Wed, 12 Jun 2024 23:58:26 +0800</pubDate>
      
      <guid>https://blog.starry-s.moe/posts/2024/leader-election/</guid>
      <description>&lt;p&gt;最近好忙，有很多想写博客的东西都没时间写，五一去了佛山的 HiFurry，本来想着整理点照片水一篇博客但没时间也没精力，所以最后想写的东西就都咽肚里就饭吃了。&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>最近好忙，有很多想写博客的东西都没时间写，五一去了佛山的 HiFurry，本来想着整理点照片水一篇博客但没时间也没精力，所以最后想写的东西就都咽肚里就饭吃了。</p>
<meting-js server="netease" type="song" id="2055270589" theme="#233333"></meting-js>
<hr>
<p>最近在折腾 Operator，就是用现成的框架写的 Controller。Operator 省去了重复且繁琐的使用 client-go 手搓 ClientSet、Informer、Lister、WorkQueue 等一大堆重复代码的步骤，只要基于已有的框架去写资源对象更新/删除时的业务处理逻辑就行了。</p>
<h2 id="leader-election-是什么">Leader Election 是什么</h2>
<p>当负载在 Kubernetes 运行时，通常会设置多个 Replicas 冗余副本，以实现高可用（HA），例如通常会将某些系统组件的 Replicas 设置为 2，就会创建两个对应的 Pods，通常这俩 Pod 会被调度到不同的节点上，在某个 Pod 挂掉时还能用另一个节点的 Pod。</p>
<p>Leader Election 机制是由“领导人选举机制”抽象而来的，可以理解为在多个“候选者”中选取某一个作为 Leader。这里的候选者指的是负载创建的多个冗余 Pod，Leader Election 机制从中选取某一个 Pod 作为 Leader，其他 Pod 则处于“待命”状态，如果 Leader Pod 出现故障，则会重新选举一个 Leader Pod。</p>
<p>Kubernetes 使用 Lease 资源（译作：租约）作为 Leader Election 的锁。和常用的 Mutex 互斥锁不同，Lease 资源会被 Leader Pod 每隔几秒钟更新一次。如果长达一段时间 Lease 没有被更新，则说明 Leader 挂掉了，其他 Pods 会竞争，尝试更新这个 Lease 锁，而成功更新了 Lease 的 Pod 会成为新的 Leader，其余 Pod 则继续处于待命状态。</p>
<p>大多数情况下，当某个资源发生更新时，我们不希望所有的冗余副本 Pod 都去处理某一个资源的更新，而是让某一个 Pod 去处理就可以了，不然会混乱（比如刷 Conflict 报错: <code>the object has been modified; please apply your changes to the latest version and try again</code>）。这时可以用到 Leader Election 机制，从多个冗余 Pod 中只选其中某一个 Pod 作为 Leader 处理资源更新，其余 Pod 只作为待命或其他用途。</p>
<p>如果你的 Controller 没有 Leader Election 机制，通常只能强行设定其 Replicas 为 1，但如果有小聪明修改了冗余数值为 2，则会出现一些问题，日志会刷大量的 Conflict 报错之类的，所以更严谨的方式是为 Controller 添加 Leader Election，以允许多 Replicas 冗余。</p>
<h2 id="举个栗子">举个栗子</h2>
<p>client-go 的样例代码中有 <a href="https://github.com/kubernetes/client-go/blob/v0.30.1/examples/leader-election/main.go">Leader Election 例子</a>，所以直接拿这个 Example 做简单的介绍了，把这个 Example 代码拷贝下来在本地跑一下。</p>
<p>首先你需要有一个 Kubernetes 集群用来调试，如果你觉得搭一个集群太麻烦，或者手里没有可供调试使用的集群的话，一个超级简单的方式是使用 <a href="https://k3d.io/">K3d</a> 在你的 Docker Runtime 中跑一个迷你版 K3s 集群。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> k3d cluster create example
</span></span><span class="line"><span class="cl"><span class="go">INFO[0000] Prep: Network
</span></span></span><span class="line"><span class="cl"><span class="go">INFO[0000] Created network &#39;k3d-example&#39;
</span></span></span><span class="line"><span class="cl"><span class="go">......
</span></span></span><span class="line"><span class="cl"><span class="go">INFO[0012] Cluster &#39;example&#39; created successfully!
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="gp">$</span> kubectl get nodes -o wide
</span></span><span class="line"><span class="cl"><span class="go">NAME                   STATUS   ROLES                  AGE   VERSION        INTERNAL-IP   EXTERNAL-IP   OS-IMAGE           KERNEL-VERSION   CONTAINER-RUNTIME
</span></span></span><span class="line"><span class="cl"><span class="go">k3d-example-server-0   Ready    control-plane,master   98s   v1.28.8+k3s1   172.19.0.2    &lt;none&gt;        K3s v1.28.8+k3s1   6.9.3-arch1-1    containerd://1.7.11-k3s2
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="gp">$</span> docker ps
</span></span><span class="line"><span class="cl"><span class="go">CONTAINER ID   IMAGE                            COMMAND                  CREATED          STATUS              PORTS                           NAMES
</span></span></span><span class="line"><span class="cl"><span class="go">a4c1367c04a2   ghcr.io/k3d-io/k3d-proxy:5.6.3   &#34;/bin/sh -c nginx-pr…&#34;   2 minutes ago    Up About a minute   80/tcp, 0.0.0.0:6443-&gt;6443/tcp  k3d-example-serverlb
</span></span></span><span class="line"><span class="cl"><span class="go">7c95a6ea069b   rancher/k3s:v1.28.8-k3s1         &#34;/bin/k3d-entrypoint…&#34;   2 minutes ago    Up 2 minutes                                        k3d-example-server-0
</span></span></span></code></pre></div><p>按照样例的 <a href="https://github.com/kubernetes/client-go/blob/v0.30.1/examples/leader-election/README.md">README</a>，在 3 个终端中运行 Leader Election 样例代码。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> go run main.go -kubeconfig<span class="o">=</span>~/.kube/config -logtostderr<span class="o">=</span><span class="nb">true</span> -lease-lock-name<span class="o">=</span>example -lease-lock-namespace<span class="o">=</span>default -id<span class="o">=</span><span class="m">1</span>
</span></span><span class="line"><span class="cl"><span class="go">I0612 22:59:20.118613   27504 leaderelection.go:250] attempting to acquire leader lease default/example...
</span></span></span><span class="line"><span class="cl"><span class="go">I0612 22:59:20.124630   27504 leaderelection.go:260] successfully acquired lease default/example
</span></span></span><span class="line"><span class="cl"><span class="go">I0612 22:59:20.124696   27504 main.go:87] Controller loop...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="gp">$</span> go run main.go -kubeconfig<span class="o">=</span>~/.kube/config -logtostderr<span class="o">=</span><span class="nb">true</span> -lease-lock-name<span class="o">=</span>example -lease-lock-namespace<span class="o">=</span>default -id<span class="o">=</span><span class="m">2</span>
</span></span><span class="line"><span class="cl"><span class="go">I0612 22:59:32.692373   27815 leaderelection.go:250] attempting to acquire leader lease default/example...
</span></span></span><span class="line"><span class="cl"><span class="go">I0612 22:59:32.695277   27815 main.go:151] new leader elected: 1
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="gp">$</span> go run main.go -kubeconfig<span class="o">=</span>~/.kube/config -logtostderr<span class="o">=</span><span class="nb">true</span> -lease-lock-name<span class="o">=</span>example -lease-lock-namespace<span class="o">=</span>default -id<span class="o">=</span><span class="m">3</span>
</span></span><span class="line"><span class="cl"><span class="go">I0612 22:59:36.424251   28089 leaderelection.go:250] attempting to acquire leader lease default/example...
</span></span></span><span class="line"><span class="cl"><span class="go">I0612 22:59:36.427674   28089 main.go:151] new leader elected: 1
</span></span></span></code></pre></div><p>按顺序在 3 个终端中依次运行样例代码，可以看到 ID 为 1 的程序最先运行所以它成了 Leader，其余两个程序则在待命中。</p>
<p>这时对 ID 1 的程序执行 Ctrl-C，发送 <code>SIGINT</code> 中断信号，让它 Context Canceled，ID 1 程序会释放 Lease 锁并结束运行，其余两个程序中的某一个则会重新竞争，其中一个变成 Leader。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> go run main.go -kubeconfig<span class="o">=</span>~/.kube/config -logtostderr<span class="o">=</span><span class="nb">true</span> -lease-lock-name<span class="o">=</span>example -lease-lock-namespace<span class="o">=</span>default -id<span class="o">=</span><span class="m">3</span>
</span></span><span class="line"><span class="cl"><span class="go">I0612 22:59:36.424251   28089 leaderelection.go:250] attempting to acquire leader lease default/example...
</span></span></span><span class="line"><span class="cl"><span class="go">I0612 22:59:36.427674   28089 main.go:151] new leader elected: 1
</span></span></span><span class="line"><span class="cl"><span class="go">I0612 23:02:56.584777   28089 leaderelection.go:260] successfully acquired lease default/example
</span></span></span><span class="line"><span class="cl"><span class="go">I0612 23:02:56.584866   28089 main.go:87] Controller loop...
</span></span></span></code></pre></div><p>查看样例程序代码，<code>leaderelection.RunOrDie</code> 的参数传递的 Config 定义了 Leader Election 机制的 Callback 回调函数以及租约相关的时间 Duration。</p>
<p><code>Callbacks</code> 回调函数分为：</p>
<ul>
<li><code>OnStartedLeading</code>: 当该程序被选举为 Leader 时，执行此回调函数，通常该回调函数启动 Controller 的 Sync 逻辑等一些操作。</li>
<li><code>OnStoppedLeading</code>: 当该程序不再是 Leader 时（可能是收到了 <code>SIGINT</code> 信号，Context Canceled 或程序出故障，很长一段时间没有去更新 Lease 锁），会执行此回调函数，执行一些资源释放等操作，然后直接 <code>os.Exit</code> 结束程序。</li>
<li><code>OnNewLeader</code>: 当其他某个程序被选举为 Leader 时，会执行此函数，一般没什么用，可以不配置。</li>
</ul>
<p>Config 的其他参数：</p>
<ul>
<li><code>Lock</code>: Lease Lock。</li>
<li><code>ReleaseOnCancel</code>: 当 Context Cancel（当前的 Leader 结束运行）时，释放当前的 Lease 锁，使得其他 Pod 可以立即进行新一轮的选举。如果设置为 false 的话，当前 Leader 挂掉后其他 Pod 并不知道当前 Leader 已经挂掉了，只有过很长一段时间，发现 Lease 锁超过了 <code>LeaseDuration</code> 时间还没被更新，才会去强行的执行新一轮的选举。</li>
<li><code>LeaseDuration</code>: 结合上方的 <code>ReleaseOnCancel</code> 的介绍，假设当前 Leader Pod 出故障了（例如被 <code>SIGKILL</code> 立即杀死，Context 来不及 Cancel，或者调试进入了 Breakpoint 断点，程序暂停），Lease 锁没被释放，但当前 Leader 出问题挂掉了，其他待命的 Pod 发现 Lease 锁已经超过 <code>LeaseDuration</code> 没有被更新，则会强行进行新一轮的选举，而原 Leader 如果还活着的话，也会执行 <code>OnStoppedLeading</code> 回调函数结束运行。</li>
<li><code>RenewDeadline</code>: Leader 每隔一段时间会更新一次 Lease 锁。</li>
<li><code>RetryPeriod</code>: 如果 Leader 更新 Lease 锁失败了，会在一段时间后重试。</li>
</ul>
<p>所以有些小朋友在调试软件时，进入断点再恢复运行时会莫名其妙的结束运行，其实就是 Leader Election 机制搞的。所以如果想调试程序，可以临时把 <code>LeaseDuration</code> 设置长一些（例如好几天），这样调试断点恢复后，程序就不会被杀死了。</p>
<h2 id="杂谈">杂谈</h2>
<p>常用的 Operator 框架都支持 Leader Election，所以基本不用手写 <code>RunOrDie</code> 这部分代码，例如 Rancher 使用的 <a href="https://github.com/rancher/wrangler/">Wrangler</a> 框架，当程序成为 Leader 时，直接执行 <a href="https://github.com/rancher/rancher/blob/v2.9.0-rc1/pkg/wrangler/context.go#L175">OnLeader</a> 回调函数启动一系列业务逻辑。而当程序还没被选为 Leader 时，只初始化 Informer Cache 等初始化步骤，不启动 Sync 相关逻辑。</p>
<p>通常 <code>sample-controller</code> 或其他简单的 Controller 在 Worker Start 执行完之后，会加一个 <code>&lt;-ctx.Done()</code> 阻塞（<a href="https://github.com/kubernetes/sample-controller/blob/master/controller.go#L182">代码位置</a>），遇到 Context Cancel 后直接结束运行。但如果加了 Leader Election 机制，当 Context Cancel 时是由 Leader Election 的 <code>OnStoppedLeading</code> 回调函数结束运行并释放 Lease 锁，所以 <code>main</code> 函数可以改为使用 <code>select {}</code> 阻塞，否则程序在 Context Cancel 时 Lease 锁还没来得及释放就由 <code>main</code> 函数结束运行了。</p>
<p>所以读到这里，可以得出结论，就算设置数量特别多的 Replicas，实际上依旧只有一个 Controller Pod 在执行真正的 Sync 逻辑，而其他 Pod 只是在观望，或者只提供一些 Web Server 功能。如果想让多个冗余 Pod 分别 Sync 不同的资源更新，需要设计一个更复杂的锁，而这又会增加一定的 API Server 请求数量……</p>]]></content:encoded>
    </item>
    
    <item>
      <title>摄影日记 - 2024 春</title>
      <link>https://blog.starry-s.moe/posts/2024/spring-2024/</link>
      <pubDate>Wed, 24 Apr 2024 23:54:04 +0800</pubDate>
      
      <guid>https://blog.starry-s.moe/posts/2024/spring-2024/</guid>
      <description>&lt;p&gt;差一点就错过了今年春天的花……&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>差一点就错过了今年春天的花……</p>
<meting-js server="netease" type="song" id="32364750" theme="#233333"></meting-js>
<blockquote>
<p>感兴趣的话还可以看看咱的<a href="/gallery/">相册</a>页面。</p>
</blockquote>
<hr>
<p>公寓楼下的花，不确定是什么品种，应该是桃花。</p>
<p><img loading="lazy" src="../../../gallery/images/20240421-114524.jpg" alt="" />

</p>
<p><img loading="lazy" src="../../../gallery/images/20240421-114518.jpg" alt="" />

</p>
<p><img loading="lazy" src="../../../gallery/images/20240421-114517.jpg" alt="" />

</p>
<p><img loading="lazy" src="../../../gallery/images/20240421-114516.jpg" alt="" />

</p>
<p><img loading="lazy" src="../../../gallery/images/20240421-114521.jpg" alt="" />

</p>
<hr>
<p>去长白岛的时候已经过了桃花的花期了，拍到的是刚开放的樱花。</p>
<p><img loading="lazy" src="../../../gallery/images/20240421-114054.jpg" alt="" />

</p>
<p><img loading="lazy" src="../../../gallery/images/20240421-114057.jpg" alt="" />

</p>
<p><img loading="lazy" src="../../../gallery/images/20240421-114058.jpg" alt="" />

</p>
<p><img loading="lazy" src="../../../gallery/images/20240421-114100.jpg" alt="" />

</p>
<p><img loading="lazy" src="../../../gallery/images/20240421-114101.jpg" alt="" />

</p>
<p><img loading="lazy" src="../../../gallery/images/20240421-114105.jpg" alt="" />

</p>
<p><img loading="lazy" src="../../../gallery/images/20240421-114108.jpg" alt="" />

</p>
<hr>
<p><img loading="lazy" src="../../../gallery/images/20240421-114112.jpg" alt="" />

</p>
<p><img loading="lazy" src="../../../gallery/images/20240421-114113.jpg" alt="" />

</p>
<p><img loading="lazy" src="../../../gallery/images/20240421-114123.jpg" alt="" />

</p>]]></content:encoded>
    </item>
    
    <item>
      <title>Arch Linux 连接小米照片打印机 1S</title>
      <link>https://blog.starry-s.moe/posts/2024/archlinux-xiaomi-photo-printer-1s/</link>
      <pubDate>Sun, 03 Mar 2024 22:49:16 +0800</pubDate>
      
      <guid>https://blog.starry-s.moe/posts/2024/archlinux-xiaomi-photo-printer-1s/</guid>
      <description>&lt;p&gt;奇怪的反图方式增加了……&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>奇怪的反图方式增加了……</p>
<meting-js server="netease" type="song" id="41652392" theme="#233333"></meting-js>
<hr>
<blockquote>
<p>参烤链接：<a href="https://wiki.archlinux.org/title/CUPS#Permissions">CUPS - ArchWiki</a>。</p>
</blockquote>
<p>安装 <code>CUPS</code> 和 <code>ghostscript</code>，启用 <code>cups.service</code>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo pacman -S cups
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo systemctl <span class="nb">enable</span> --now cups.service
</span></span></code></pre></div><p>小米的这个照片打印机支持免驱 <a href="https://en.wikipedia.org/wiki/AirPrint">AirPrint</a>，所以直接使用 <code>lpadmin</code> 添加打印机就行，不用安装驱动（也根本找不到对应的 Linux 驱动），只需要先在路由器中查询打印机的 IP 地址。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo lpadmin -p <span class="s2">&#34;Xiaomi-Photo-AirPrint&#34;</span> -E -v <span class="s2">&#34;ipp://192.168.x.x/ipp/print&#34;</span> -m everywhere
</span></span></code></pre></div><p>之后打印照片时就可以选择已添加的打印机设备了。</p>
<p><img loading="lazy" src="images/1.png" alt="" />

</p>
<p>初次打印时需要改一下打印的纸张大小为 4x6 英寸，不然照片尺寸会有问题，然后图片的质量可以改成最高。</p>
<p>照片打印出来会比屏幕上看到的更有内种感觉，打印的照片会有一些偏色，但个人认为这种色调害挺好看的。</p>
<p><img loading="lazy" src="images/2.jpg" alt="" />

</p>]]></content:encoded>
    </item>
    
    <item>
      <title>初探容器网络</title>
      <link>https://blog.starry-s.moe/posts/2024/container-network-1/</link>
      <pubDate>Mon, 26 Feb 2024 19:21:28 +0800</pubDate>
      
      <guid>https://blog.starry-s.moe/posts/2024/container-network-1/</guid>
      <description>&lt;p&gt;稍微折腾一下容器网络相关的东西……&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>稍微折腾一下容器网络相关的东西……</p>
<meting-js server="netease" type="song" id="1388992194" theme="#233333"></meting-js>
<h2 id="linux-网络命名空间">Linux 网络命名空间</h2>
<p>在熟悉容器网络之前，首先来看一下 Linux 网络命名空间 (Network Namespace) 这个东西。Linux 提供了多个不同种类的 Namespace，可以用 <code>lsns</code> 命令查看。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> lsns
</span></span><span class="line"><span class="cl"><span class="go">        NS TYPE   NPROCS   PID USER     COMMAND
</span></span></span><span class="line"><span class="cl"><span class="go">4026531834 time        2  2251 starry-s -zsh
</span></span></span><span class="line"><span class="cl"><span class="go">4026531835 cgroup      2  2251 starry-s -zsh
</span></span></span><span class="line"><span class="cl"><span class="go">4026531836 pid         2  2251 starry-s -zsh
</span></span></span><span class="line"><span class="cl"><span class="go">4026531837 user        2  2251 starry-s -zsh
</span></span></span><span class="line"><span class="cl"><span class="go">4026531838 uts         2  2251 starry-s -zsh
</span></span></span><span class="line"><span class="cl"><span class="go">4026531839 ipc         2  2251 starry-s -zsh
</span></span></span><span class="line"><span class="cl"><span class="go">4026531840 net         2  2251 starry-s -zsh
</span></span></span><span class="line"><span class="cl"><span class="go">4026531841 mnt         2  2251 starry-s -zsh
</span></span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span></code></pre></div><p>参考 <a href="https://man7.org/linux/man-pages/man7/network_namespaces.7.html">network_namespace manpage</a>，Network Namespace 是 Linux 实现网络资源隔离的功能，不同的 Network Namespace 拥有不同的网卡、ARP、路由表等数据。可以使用 <code>iproute2</code> 工具的 <code>ip</code> 命令对 Linux Network Namespace 执行一系列的操作。</p>
<blockquote>
<p>本篇介绍的指令不会系统产生损坏，但建议在虚拟机或一个用于测试的系统上执行 Network Namespace 相关操作，以便于执行重启等暴力操作。</p>
</blockquote>
<p>开始之前，先安装 <code>net-tools</code> 网络工具包。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo pacman -S net-tools
</span></span></code></pre></div><p>查看设备中已有的 Network Namespace。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> ip netns list
</span></span><span class="line"><span class="cl"><span class="gp">$</span> ip netns ls
</span></span></code></pre></div><p><code>ip netns</code> 命令会列出 <code>/var/run/netns/</code> 目录下存在的 Network Namespace，如果之前没有使用 <code>ip</code> 命令创建过 netns，以上命令基本不会有输出（除非有别的工具也修改了这个目录）。首先创建两个 Network Namespace。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip netns add ns0
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip netns add ns1
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip netns ls
</span></span><span class="line"><span class="cl"><span class="go">ns0
</span></span></span><span class="line"><span class="cl"><span class="go">ns1
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">$</span> ls /var/run/netns/
</span></span><span class="line"><span class="cl"><span class="go">ns0 ns1
</span></span></span></code></pre></div><p>每个 Network Namespace 拥有不同的网卡、路由表、ARP 表等信息，可以使用 <code>ip -n [NAMESPACE]</code> 对某个 netns 进行操作，或通过 <code>ip netns exec</code> 在不同的 netns 下执行命令。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns0 link
</span></span><span class="line"><span class="cl"><span class="go">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="gp">$</span> sudo ip netns <span class="nb">exec</span> ns0 ip link
</span></span><span class="line"><span class="cl"><span class="go">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="gp">$</span> sudo ip netns <span class="nb">exec</span> ns0 route
</span></span><span class="line"><span class="cl"><span class="go">Kernel IP routing table
</span></span></span><span class="line"><span class="cl"><span class="go">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="gp">$</span> sudo ip netns <span class="nb">exec</span> ns0 arp
</span></span></code></pre></div><h3 id="veth-pair-连接-network-namespace">veth pair 连接 Network Namespace</h3>
<p>新建的 netns 只有一个 DOWN 状态的回环接口，没有 ARP 和路由表信息，如果想在不同的 netns 之间通信，需要建立 veth pair（Virtual Cabel），把 netns 连接起来。</p>
<p>可以使用 <code>ip link add type veth</code> 创建一对 veth pair，注意 veth pair 是成对出现的，可以在创建 veth pair 时指定这对 veth pair 名称。</p>
<p>首先看一下系统自带的接口信息，默认情况下系统有一个 <code>lo</code> 回环接口和一个 <code>eth0</code> (被重命名为 <code>enp*s*</code> 的接口)，如果运行了 Docker，还会有一个 <code>docker0</code> 接口。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link
</span></span><span class="line"><span class="cl"><span class="go">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class="line"><span class="cl"><span class="go">2: enp1s0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether ab:cd:ef:89:8f:f5 brd ff:ff:ff:ff:ff:ff
</span></span></span><span class="line"><span class="cl"><span class="go">3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default 
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 02:42:b7:a9:6a:55 brd ff:ff:ff:ff:ff:ff
</span></span></span></code></pre></div><p>创建一对 veth pair 名为 <code>veth0</code> 和 <code>veth1</code>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link add veth0 <span class="nb">type</span> veth peer name veth1
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link
</span></span><span class="line"><span class="cl"><span class="go">......
</span></span></span><span class="line"><span class="cl"><span class="go">4: veth1@veth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 5e:7a:4e:96:b1:df brd ff:ff:ff:ff:ff:ff
</span></span></span><span class="line"><span class="cl"><span class="go">5: veth0@veth1: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 5e:5b:51:12:d0:b6 brd ff:ff:ff:ff:ff:ff
</span></span></span></code></pre></div><p>之后使用 <code>ip link set</code> 将这对 veth pair 分配到不同的 netns 中。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link <span class="nb">set</span> veth0 netns ns0
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link <span class="nb">set</span> veth1 netns ns1
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns0 link
</span></span><span class="line"><span class="cl"><span class="go">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class="line"><span class="cl"><span class="go">5: veth0@if4: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 5e:5b:51:12:d0:b6 brd ff:ff:ff:ff:ff:ff link-netns ns1
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">$</span> sudo ip -n ns1 link
</span></span><span class="line"><span class="cl"><span class="go">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class="line"><span class="cl"><span class="go">4: veth1@if5: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 5e:7a:4e:96:b1:df brd ff:ff:ff:ff:ff:ff link-netns ns0
</span></span></span></code></pre></div><p>使用 <code>ip addr add</code> 为 veth pair 接口创建 IP 地址，并使用 <code>ip link set [INTERFACE] up</code> 启动网卡接口。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns0 addr add 10.0.0.100/24 dev veth0
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns1 addr add 10.0.0.101/24 dev veth1
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns0 link <span class="nb">set</span> veth0 up
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns1 link <span class="nb">set</span> veth1 up
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns0 addr
</span></span><span class="line"><span class="cl"><span class="go">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class="line"><span class="cl"><span class="go">5: veth0@if4: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 5e:5b:51:12:d0:b6 brd ff:ff:ff:ff:ff:ff link-netns ns1
</span></span></span><span class="line"><span class="cl"><span class="go">    inet 10.0.0.100/24 scope global veth0
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span><span class="line"><span class="cl"><span class="go">    inet6 fe80::5c5b:51ff:fe12:d0b6/64 scope link proto kernel_ll 
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">$</span> sudo ip -n ns1 addr
</span></span><span class="line"><span class="cl"><span class="go">1: lo: &lt;LOOPBACK&gt; mtu 65536 qdisc noop state DOWN group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class="line"><span class="cl"><span class="go">4: veth1@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 5e:7a:4e:96:b1:df brd ff:ff:ff:ff:ff:ff link-netns ns0
</span></span></span><span class="line"><span class="cl"><span class="go">    inet 10.0.0.101/24 scope global veth1
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span><span class="line"><span class="cl"><span class="go">    inet6 fe80::5c7a:4eff:fe96:b1df/64 scope link proto kernel_ll 
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span></code></pre></div><p><code>ip addr add</code> 命令在添加 IP 地址时会自动创建路由表信息。现在两个 netns 之间可通过 veth pair 互相通信。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns0 route
</span></span><span class="line"><span class="cl"><span class="go">10.0.0.0/24 dev veth0 proto kernel scope link src 10.0.0.100 
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">$</span> sudo ip -n ns1 route
</span></span><span class="line"><span class="cl"><span class="go">10.0.0.0/24 dev veth1 proto kernel scope link src 10.0.0.101 
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">$</span> sudo ip netns <span class="nb">exec</span> ns0 ping -c <span class="m">1</span> 10.0.0.101
</span></span><span class="line"><span class="cl"><span class="go">PING 10.0.0.101 (10.0.0.101) 56(84) bytes of data.
</span></span></span><span class="line"><span class="cl"><span class="go">64 bytes from 10.0.0.101: icmp_seq=1 ttl=64 time=0.051 ms
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="go">--- 10.0.0.101 ping statistics ---
</span></span></span><span class="line"><span class="cl"><span class="go">1 packets transmitted, 1 received, 0% packet loss, time 0ms
</span></span></span><span class="line"><span class="cl"><span class="go">rtt min/avg/max/mdev = 0.051/0.051/0.051/0.000 ms
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">$</span> sudo ip netns <span class="nb">exec</span> ns1 ping -c <span class="m">1</span> 10.0.0.100
</span></span><span class="line"><span class="cl"><span class="go">PING 10.0.0.100 (10.0.0.100) 56(84) bytes of data.
</span></span></span><span class="line"><span class="cl"><span class="go">64 bytes from 10.0.0.100: icmp_seq=1 ttl=64 time=0.040 ms
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="go">--- 10.0.0.100 ping statistics ---
</span></span></span><span class="line"><span class="cl"><span class="go">1 packets transmitted, 1 received, 0% packet loss, time 0ms
</span></span></span><span class="line"><span class="cl"><span class="go">rtt min/avg/max/mdev = 0.040/0.040/0.040/0.000 ms
</span></span></span></code></pre></div><p>到这里，<code>ns0</code> 和 <code>ns1</code> 两个 Network Namespace 之间的拓扑图如下。</p>
<p><img loading="lazy" src="images/veth.webp" alt="" />

</p>
<h3 id="使用-bridge-连接多个-network-namespace">使用 bridge 连接多个 Network Namespace</h3>
<p>veth pair 只能用于两个 netns 之间的通信，如果需要多个 netns 访问到同一个网络中，需要配置桥接网络。</p>
<p>重启系统（清理掉之前创建的 netns 和 veth pair），之后重新建立 <code>ns0</code>, <code>ns1</code> 和 <code>ns2</code> 三个 Network Namespace。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip netns add ns0
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip netns add ns1
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip netns add ns2
</span></span></code></pre></div><p>使用 <code>ip link add</code> 创建一个桥接接口，并建立三对 veth pair，用于连接 <code>br0</code> 和上述三个 netns。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link add br0 <span class="nb">type</span> bridge
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link add veth0-br <span class="nb">type</span> veth peer name veth0
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link add veth1-br <span class="nb">type</span> veth peer name veth1
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link add veth2-br <span class="nb">type</span> veth peer name veth2
</span></span><span class="line"><span class="cl"><span class="gp">$</span> ip link
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go">4: br0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether be:60:00:25:c5:37 brd ff:ff:ff:ff:ff:ff
</span></span></span><span class="line"><span class="cl"><span class="go">5: veth0@veth0-br: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 5e:5b:51:12:d0:b6 brd ff:ff:ff:ff:ff:ff
</span></span></span><span class="line"><span class="cl"><span class="go">6: veth0-br@veth0: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 72:01:3d:42:16:8c brd ff:ff:ff:ff:ff:ff
</span></span></span><span class="line"><span class="cl"><span class="go">7: veth1@veth1-br: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 5e:7a:4e:96:b1:df brd ff:ff:ff:ff:ff:ff
</span></span></span><span class="line"><span class="cl"><span class="go">8: veth1-br@veth1: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 1e:13:96:f1:b6:9d brd ff:ff:ff:ff:ff:ff
</span></span></span><span class="line"><span class="cl"><span class="go">9: veth2@veth2-br: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 62:13:73:b6:5d:f9 brd ff:ff:ff:ff:ff:ff
</span></span></span><span class="line"><span class="cl"><span class="go">10: veth2-br@veth2: &lt;BROADCAST,MULTICAST,M-DOWN&gt; mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether f2:e6:df:92:de:71 brd ff:ff:ff:ff:ff:ff
</span></span></span></code></pre></div><p>把 <code>veth0</code>, <code>veth1</code>, <code>veth2</code> 分别放到 <code>ns0</code>, <code>ns1</code> 和 <code>ns2</code> 三个 Network Namespace 中，并将他们重命名为 <code>eth0</code>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link <span class="nb">set</span> dev veth0 netns ns0
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link <span class="nb">set</span> dev veth1 netns ns1
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link <span class="nb">set</span> dev veth2 netns ns2
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns0 link <span class="nb">set</span> dev veth0 name eth0
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns1 link <span class="nb">set</span> dev veth1 name eth0
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns2 link <span class="nb">set</span> dev veth2 name eth0
</span></span></code></pre></div><p>并把 <code>veth0-br</code>, <code>veth1-br</code>, <code>veth2-br</code> 分别连接到 <code>br0</code> 桥接网卡中。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link <span class="nb">set</span> dev veth0-br master br0
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link <span class="nb">set</span> dev veth1-br master br0
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link <span class="nb">set</span> dev veth2-br master br0
</span></span></code></pre></div><p>启用所有的网卡接口（为了能 ping 通每个 netns 的 <code>127.0.0.1</code>，将每个 ns 的 <code>lo</code> 回环接口也启动）。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link <span class="nb">set</span> dev br0 up
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link <span class="nb">set</span> veth0-br up
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link <span class="nb">set</span> veth1-br up
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link <span class="nb">set</span> veth2-br up
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns0 link <span class="nb">set</span> eth0 up
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns1 link <span class="nb">set</span> eth0 up
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns2 link <span class="nb">set</span> eth0 up
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns0 link <span class="nb">set</span> lo up
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns1 link <span class="nb">set</span> lo up
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns2 link <span class="nb">set</span> lo up
</span></span></code></pre></div><p>为 <code>br0</code> 和 netns 中的 veth 接口 （<code>eth0</code>）添加 IP 地址。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip addr add 10.1.1.1/24 dev br0
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns0 addr add 10.1.1.10/24 dev eth0
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns1 addr add 10.1.1.11/24 dev eth0
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns2 addr add 10.1.1.12/24 dev eth0
</span></span></code></pre></div><p>查看一下 <code>br0</code> 和 netns 中的 <code>eth0</code> 接口的 IP 地址。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> ip a
</span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go">4: br0: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether be:60:00:25:c5:37 brd ff:ff:ff:ff:ff:ff
</span></span></span><span class="line"><span class="cl"><span class="go">    inet 10.0.0.1/24 scope global br0
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span><span class="line"><span class="cl"><span class="go">6: veth0-br@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master br0 state UP group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 72:01:3d:42:16:8c brd ff:ff:ff:ff:ff:ff link-netns ns0
</span></span></span><span class="line"><span class="cl"><span class="go">    inet6 fe80::7001:3dff:fe42:168c/64 scope link proto kernel_ll 
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span><span class="line"><span class="cl"><span class="go">8: veth1-br@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master br0 state UP group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 1e:13:96:f1:b6:9d brd ff:ff:ff:ff:ff:ff link-netns ns1
</span></span></span><span class="line"><span class="cl"><span class="go">    inet6 fe80::1c13:96ff:fef1:b69d/64 scope link proto kernel_ll 
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span><span class="line"><span class="cl"><span class="go">10: veth2-br@if9: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master br0 state UP group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether f2:e6:df:92:de:71 brd ff:ff:ff:ff:ff:ff link-netns ns2
</span></span></span><span class="line"><span class="cl"><span class="go">    inet6 fe80::f0e6:dfff:fe92:de71/64 scope link proto kernel_ll 
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">$</span> sudo ip -n ns0 a
</span></span><span class="line"><span class="cl"><span class="go">5: eth0@if6: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 5e:5b:51:12:d0:b6 brd ff:ff:ff:ff:ff:ff link-netnsid 0
</span></span></span><span class="line"><span class="cl"><span class="go">    inet 10.1.1.10/24 scope global eth0
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span><span class="line"><span class="cl"><span class="go">    inet6 fe80::5c5b:51ff:fe12:d0b6/64 scope link proto kernel_ll 
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">$</span> sudo ip -n ns1 a
</span></span><span class="line"><span class="cl"><span class="go">7: eth0@if8: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 5e:7a:4e:96:b1:df brd ff:ff:ff:ff:ff:ff link-netnsid 0
</span></span></span><span class="line"><span class="cl"><span class="go">    inet 10.1.1.11/24 scope global eth0
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span><span class="line"><span class="cl"><span class="go">    inet6 fe80::5c7a:4eff:fe96:b1df/64 scope link proto kernel_ll 
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">$</span> sudo ip -n ns2 a
</span></span><span class="line"><span class="cl"><span class="go">9: eth0@if10: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 62:13:73:b6:5d:f9 brd ff:ff:ff:ff:ff:ff link-netnsid 0
</span></span></span><span class="line"><span class="cl"><span class="go">    inet 10.1.1.12/24 scope global eth0
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span><span class="line"><span class="cl"><span class="go">    inet6 fe80::6013:73ff:feb6:5df9/64 scope link proto kernel_ll 
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span></code></pre></div><p>此时在主机上可以 ping 通三个 netns 的 IP 地址。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> ping -c <span class="m">1</span> 10.1.1.10
</span></span><span class="line"><span class="cl"><span class="go">PING 10.1.1.10 (10.1.1.10) 56(84) bytes of data.
</span></span></span><span class="line"><span class="cl"><span class="go">64 bytes from 10.1.1.10: icmp_seq=1 ttl=64 time=0.130 ms
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">$</span> ping -c <span class="m">1</span> 10.1.1.11
</span></span><span class="line"><span class="cl"><span class="go">PING 10.1.1.11 (10.1.1.11) 56(84) bytes of data.
</span></span></span><span class="line"><span class="cl"><span class="go">64 bytes from 10.1.1.11: icmp_seq=1 ttl=64 time=0.117 ms
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">$</span> ping -c <span class="m">1</span> 10.1.1.12
</span></span><span class="line"><span class="cl"><span class="go">PING 10.1.1.12 (10.1.1.12) 56(84) bytes of data.
</span></span></span><span class="line"><span class="cl"><span class="go">64 bytes from 10.1.1.12: icmp_seq=1 ttl=64 time=0.119 ms
</span></span></span></code></pre></div><p>三个 netns 也可以访问主机的 IP 地址 <code>10.1.1.1</code>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip netns <span class="nb">exec</span> ns0 ping -c <span class="m">1</span> 10.1.1.1
</span></span><span class="line"><span class="cl"><span class="go">PING 10.1.1.1 (10.1.1.1) 56(84) bytes of data.
</span></span></span><span class="line"><span class="cl"><span class="go">64 bytes from 10.1.1.1: icmp_seq=1 ttl=64 time=0.076 ms
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">$</span> sudo ip netns <span class="nb">exec</span> ns1 ping -c <span class="m">1</span> 10.1.1.1
</span></span><span class="line"><span class="cl"><span class="go">PING 10.1.1.1 (10.1.1.1) 56(84) bytes of data.
</span></span></span><span class="line"><span class="cl"><span class="go">64 bytes from 10.1.1.1: icmp_seq=1 ttl=64 time=0.071 ms
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">$</span> sudo ip netns <span class="nb">exec</span> ns2 ping -c <span class="m">1</span> 10.1.1.1
</span></span><span class="line"><span class="cl"><span class="go">PING 10.1.1.1 (10.1.1.1) 56(84) bytes of data.
</span></span></span><span class="line"><span class="cl"><span class="go">64 bytes from 10.1.1.1: icmp_seq=1 ttl=64 time=0.072 ms
</span></span></span></code></pre></div><p>默认情况下 Linux 会把 bridge 的二层转发（交换机）功能禁用掉，因此不同的 netns 之间仍无法互相访问。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip netns <span class="nb">exec</span> ns0 ping -c <span class="m">1</span> -W <span class="m">5</span> 10.1.1.11
</span></span><span class="line"><span class="cl"><span class="go">PING 10.1.1.11 (10.1.1.11) 56(84) bytes of data.
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="go">--- 10.1.1.11 ping statistics ---
</span></span></span><span class="line"><span class="cl"><span class="go">1 packets transmitted, 0 received, 100% packet loss, time 0ms
</span></span></span></code></pre></div><p>使用 IP 桌子，激活桥接接口的转发功能。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo iptables -A FORWARD -i br0 -j ACCEPT
</span></span></code></pre></div><p>此时不同的 netns 之间可以互相 ping 通了。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip netns <span class="nb">exec</span> ns0 ping 10.1.1.12
</span></span><span class="line"><span class="cl"><span class="go">PING 10.1.1.12 (10.1.1.12) 56(84) bytes of data.
</span></span></span><span class="line"><span class="cl"><span class="go">64 bytes from 10.1.1.12: icmp_seq=1 ttl=64 time=0.148 ms
</span></span></span></code></pre></div><p>到这里有关 Linux Network Namespace 的配置就可以完美的告一段落了，咱创建了三个 netns，它们之间可以通过 <code>10.1.1.0/24</code> 这一个网段通过 bridge 桥接网卡和 veth pair 实现互相二层（交换机）访问，此时的网络拓扑图变成了下面这样子。</p>
<p><img loading="lazy" src="images/veth-bridge.webp" alt="" />

</p>
<hr>
<p>如果想要更进一步，要实现 netns 内访问其他网段的 IP 地址，还需要再做一些配置，让主机实现网关功能，并配置 NAT，让主机实现 3 层地址转发（路由器）。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip netns <span class="nb">exec</span> ns0 ping -c <span class="m">1</span> 8.8.8.8
</span></span><span class="line"><span class="cl"><span class="go">ping: connect: Network is unreachable
</span></span></span></code></pre></div><p>首先需要将主机的网卡（咱这里为 <code>enp1s0</code>，不同系统可能不一样）也添加到将桥接网卡 <code>br0</code> 中，这里要注意把主机的网卡 <code>enp1s0</code> 添加到桥接网卡 <code>br0</code> 后，要把 <code>enp1s0</code> 网卡上的 IP 地址（咱这里为 <code>192.168.122.101/24</code>）改到桥接网卡 <code>br0</code> 上，不然过一段时间后会网络中断。</p>
<blockquote>
<p>这里<strong>不要</strong> ssh 远程操作。</p>
</blockquote>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link <span class="nb">set</span> enp1s0 master br0
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip addr del 192.168.122.101/24 dev enp1s0
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip addr add 192.168.122.101/24 dev br0
</span></span></code></pre></div><p>手动为 netns 设定默认网关 <code>10.1.1.1/24</code>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns0 route add default via 10.1.1.1
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns1 route add default via 10.1.1.1
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns2 route add default via 10.1.1.1
</span></span></code></pre></div><p>接下来使用 IP 桌子配置 IP 地址转发，这里的指令和之前配置 Linux 主机做路由器是一样的。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo iptables --table nat -A POSTROUTING -s 10.1.1.0/24 -j MASQUERADE
</span></span></code></pre></div><p>查看一下 netns 中的路由表，这时的默认流量会走 <code>10.1.1.1</code> 网关。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns0 route
</span></span><span class="line"><span class="cl"><span class="go">default via 10.1.1.1 dev eth0 
</span></span></span><span class="line"><span class="cl"><span class="go">10.1.1.0/24 dev eth0 proto kernel scope link src 10.1.1.10
</span></span></span></code></pre></div><p>到这里如果不出意外的话，三个 netns 已经具备访问公网的能力了。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip netns <span class="nb">exec</span> ns0 ping -c <span class="m">1</span> 8.8.8.8
</span></span><span class="line"><span class="cl"><span class="go">PING 8.8.8.8 (8.8.8.8) 56(84) bytes of data.
</span></span></span><span class="line"><span class="cl"><span class="go">64 bytes from 8.8.8.8: icmp_seq=1 ttl=112 time=66.0 ms
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="go">--- 8.8.8.8 ping statistics ---
</span></span></span><span class="line"><span class="cl"><span class="go">1 packets transmitted, 1 received, 0% packet loss, time 0ms
</span></span></span><span class="line"><span class="cl"><span class="go">rtt min/avg/max/mdev = 65.964/65.964/65.964/0.000 ms
</span></span></span></code></pre></div><h2 id="容器网络">容器网络</h2>
<p>其实上面咱演示的使用 bridge 桥接网卡 + veth pair 配置多个 Network Namespace 互相访问的这个网络模型基本上就和 Docker 默认的 <code>bridge</code> 网络模型没啥区别了。</p>
<p>只是 Docker 使用 <a href="https://github.com/opencontainers/runc/tree/main/libcontainer">runc/libcontainer</a> 没有把容器对应的 Network Namespace 文件放到 <code>/var/run/netns/</code> 目录，使用 <code>ip netns</code> 命令发现不到它。不过带胶布，可以把 Docker 容器中应用的 Network Namespace 对应文件软链接到 <code>/var/run/netns/</code> 目录中，再使用 <code>ip</code> 命令执行一些操作。</p>
<p>首先跑一个 <code>nginx</code> 容器，使用 <code>docker inspect</code> 获取进程的 PID。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> docker run -dit --name nginx -p 80:80 nginx
</span></span><span class="line"><span class="cl"><span class="gp">$</span> docker inspect --format <span class="s1">&#39;{{.State.Pid}}&#39;</span> nginx
</span></span><span class="line"><span class="cl"><span class="go">993
</span></span></span></code></pre></div><p>创建软链接，将进程的 netns 文件链接到 <code>/var/run/netns</code> 目录。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo mkdir -p /var/run/netns
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ln -s /proc/993/ns/net /var/run/netns/ns-993
</span></span><span class="line"><span class="cl"><span class="gp">$</span> ip netns
</span></span><span class="line"><span class="cl"><span class="go">ns-993
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">$</span> sudo ip netns <span class="nb">exec</span> ns-993 ip addr
</span></span><span class="line"><span class="cl"><span class="go">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class="line"><span class="cl"><span class="go">    inet 127.0.0.1/8 scope host lo
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span><span class="line"><span class="cl"><span class="go">4: eth0@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default 
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
</span></span></span><span class="line"><span class="cl"><span class="go">    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span></code></pre></div><p>之后可以像上面那样，再建立一对 veth pair，为容器创建 “第二个网卡” <code>eth1</code>，实现主机和容器之间的访问。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link add eth0-ns-993 <span class="nb">type</span> veth peer name veth-ns-993
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link <span class="nb">set</span> eth0-ns-993 netns ns-993
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns-993 link <span class="nb">set</span> dev eth0-ns-993 name eth1
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns-993 addr
</span></span><span class="line"><span class="cl"><span class="go">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
</span></span></span><span class="line"><span class="cl"><span class="go">    inet 127.0.0.1/8 scope host lo
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span><span class="line"><span class="cl"><span class="go">4: eth0@if5: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default 
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
</span></span></span><span class="line"><span class="cl"><span class="go">    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
</span></span></span><span class="line"><span class="cl"><span class="go">       valid_lft forever preferred_lft forever
</span></span></span><span class="line"><span class="cl"><span class="go">9: eth1@if8: &lt;BROADCAST,MULTICAST&gt; mtu 1500 qdisc noop state DOWN group default qlen 1000
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 36:57:fa:63:3b:f0 brd ff:ff:ff:ff:ff:ff link-netnsid 0
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="gp">$</span> sudo ip addr add 10.1.0.1/24 dev veth-ns-993
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns-993 addr add 10.1.0.2/24 dev eth1
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip link <span class="nb">set</span> dev veth-ns-993 up
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo ip -n ns-993 link <span class="nb">set</span> dev eth1 up
</span></span><span class="line"><span class="cl"><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="gp">$</span> ping 10.1.0.2
</span></span><span class="line"><span class="cl"><span class="go">PING 10.1.0.2 (10.1.0.2) 56(84) bytes of data.
</span></span></span><span class="line"><span class="cl"><span class="go">64 bytes from 10.1.0.2: icmp_seq=1 ttl=64 time=0.040 ms
</span></span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="gp">$</span> curl 10.1.0.2
</span></span><span class="line"><span class="cl"><span class="go">&lt;!DOCTYPE html&gt;
</span></span></span><span class="line"><span class="cl"><span class="go">&lt;html&gt;
</span></span></span><span class="line"><span class="cl"><span class="go">&lt;head&gt;
</span></span></span><span class="line"><span class="cl"><span class="go">&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</span></span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span></code></pre></div><p>看吧，就是这么的简单（确信）。</p>
<p>所以在运行了 Docker 的主机上执行 <code>ip</code> 命令有时能看到一大堆 <code>veth</code> 开头的网卡设备名，到这里我们就能明白这些实际上是 veth pair，一端连接到了 <code>docker0</code> 桥接网卡上，另一端则连接在 Docker 容器的 Network Namespace 中。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> ip l
</span></span><span class="line"><span class="cl"><span class="go">3: docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP mode DEFAULT group default 
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 02:42:48:1b:aa:e0 brd ff:ff:ff:ff:ff:ff
</span></span></span><span class="line"><span class="cl"><span class="go">5: veth077b91e@if4: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue master docker0 state UP mode DEFAULT group default 
</span></span></span><span class="line"><span class="cl"><span class="go">    link/ether 6e:29:0d:fb:d2:43 brd ff:ff:ff:ff:ff:ff link-netnsid 0
</span></span></span></code></pre></div><h2 id="kubernetes-pod">Kubernetes Pod</h2>
<p>众所周知，Kubernetes 的一个 Pod 中可以包含多个容器，这些容器共用一个网络命名空间，不同容器运行的程序可以直接通过 <code>127.0.0.1</code> 回环地址互相访问。这里需要补充一个萌新容易混淆的概念就是，Linux 的 Namespace 和 Kubernetes 的 Namespace 不是一个东西，前者是 Linux 内核 Level 的特性，后者是 Kubernetes API Server Level 的功能，虽然都叫 Namespace 但他俩不是一个东西。</p>
<p>那么 Kubernetes 的 Pod 是如何实现多个容器共用一个 Network Namespace 的呢？之前用过 Kubernetes 的小朋友可能会注意到他们的 Container Runtime 中总能看到名叫 <code>pause</code> 的容器，这又是干什么的呢？</p>
<p>Docker 的网络模型除了默认的 <code>bridge</code> 之外，还有 <code>host</code>, <code>none</code> 和 <code>container</code> 这几种。其中 <code>host</code> 是指和主机共用同一个网络命名空间，<code>none</code> 是容器的 Network Namespace 不配置任何额外的网络。而 <code>container</code> 网络模型则是用来指定一个已有的容器，和他共用同一个 Network Namespace。</p>
<p>Kubernetes 的 Pod 需要让多个容器共用同一个 Network Namespace，所以需要先找一个容器创建 Network Namespace，再让其他容器加入到这个预先创建好的 Network Namespace 中。让 Pod 中任何一个容器作为创建 Network Namespace 的容器都不合适，所以就出来了一个 <code>pause</code> 容器，这个容器体积很小，运行之后其进程永远处于休眠（pause）状态，且 pause 容器的进程 PID 为 1，因为除了创建网络命名空间外，<code>pause</code> 容器还创建了 Linux 进程命名空间，用于回收僵尸进程。</p>
<p>Pause 容器的源码可以在 <a href="https://github.com/kubernetes/kubernetes/blob/master/build/pause/linux/pause.c">这里</a> 找到，可以看到它主要确保自己的 PID 为 1，处理一些 Linux Signal 之外，其余时间一直都在 <code>pause</code>。</p>
<p>可以用 Docker 的 <code>container</code> 网络模型模拟一个 Kubernetes 的 Pod，因为想不出什么太合适的栗子，所以这个 “Pod” 里运行了一个 nginx server 和一个 registry server。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> docker run -d --name pause -p 8080:80 -p 5000:5000 --ipc<span class="o">=</span>shareable rancher/mirrored-pause:3.6
</span></span><span class="line"><span class="cl"><span class="gp">$</span> docker run -d --name nginx --net<span class="o">=</span>container:pause --ipc<span class="o">=</span>container:pause --pid<span class="o">=</span>container:pause nginx
</span></span><span class="line"><span class="cl"><span class="gp">$</span> docker run -d --name registry --net<span class="o">=</span>container:pause --ipc<span class="o">=</span>container:pause --pid<span class="o">=</span>container:pause registry
</span></span><span class="line"><span class="cl"><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="gp">$</span> docker ps
</span></span><span class="line"><span class="cl"><span class="go">CONTAINER ID   IMAGE                        COMMAND                  CREATED         STATUS         PORTS                                                                              NAMES
</span></span></span><span class="line"><span class="cl"><span class="go">eaace8974956   registry                     &#34;/entrypoint.sh /etc…&#34;   2 minutes ago   Up 2 minutes                                                                                      registry
</span></span></span><span class="line"><span class="cl"><span class="go">247ed1ca07e3   nginx                        &#34;/docker-entrypoint.…&#34;   2 minutes ago   Up 2 minutes                                                                                      nginx
</span></span></span><span class="line"><span class="cl"><span class="go">6cdf835a09f0   rancher/mirrored-pause:3.6   &#34;/pause&#34;                 2 minutes ago   Up 2 minutes   0.0.0.0:5000-&gt;5000/tcp, :::5000-&gt;5000/tcp, 0.0.0.0:8080-&gt;80/tcp, :::8080-&gt;80/tcp   pause
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="err">
</span></span></span><span class="line"><span class="cl"><span class="err"></span><span class="gp">$</span> curl 127.0.0.1:8080
</span></span><span class="line"><span class="cl"><span class="go">&lt;!DOCTYPE html&gt;
</span></span></span><span class="line"><span class="cl"><span class="go">&lt;html&gt;
</span></span></span><span class="line"><span class="cl"><span class="go">&lt;head&gt;
</span></span></span><span class="line"><span class="cl"><span class="go">&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</span></span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span><span class="line"><span class="cl"><span class="go"></span><span class="gp">$</span> docker login 127.0.0.1:5000
</span></span><span class="line"><span class="cl"><span class="go">Username: admin
</span></span></span><span class="line"><span class="cl"><span class="go">Password: 
</span></span></span><span class="line"><span class="cl"><span class="go">Login Succeeded
</span></span></span></code></pre></div>]]></content:encoded>
    </item>
    
    <item>
      <title>K3s &#43; Multus CNI 插件使用 Macvlan</title>
      <link>https://blog.starry-s.moe/posts/2024/k3s-multus-macvlan/</link>
      <pubDate>Tue, 30 Jan 2024 18:52:00 +0800</pubDate>
      
      <guid>https://blog.starry-s.moe/posts/2024/k3s-multus-macvlan/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://k3s.io/&#34;&gt;K3s&lt;/a&gt; 是一个轻量的 Kubernetes 集群，&lt;a href=&#34;https://github.com/k8snetworkplumbingwg/multus-cni&#34;&gt;Multus&lt;/a&gt; 是一个用于给 Pod 创建多个网络接口的 CNI (Container Network Interface) 插件，其创建的接口支持 &lt;code&gt;macvlan&lt;/code&gt;。&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p><a href="https://k3s.io/">K3s</a> 是一个轻量的 Kubernetes 集群，<a href="https://github.com/k8snetworkplumbingwg/multus-cni">Multus</a> 是一个用于给 Pod 创建多个网络接口的 CNI (Container Network Interface) 插件，其创建的接口支持 <code>macvlan</code>。</p>
<meting-js server="netease" type="song" id="4017232" theme="#233333"></meting-js>
<hr>
<h2 id="啥是-macvlan">啥是 Macvlan</h2>
<p>字面意思，根据 MAC 地址划分的虚拟子网 (Vlan) 就是 macvlan，网上能搜到很多有关 Macvlan 的介绍，这里不再过多描述。</p>
<p>与之相对应的还有一个叫 ipvlan，是通过 IP 地址划分的虚拟子网。</p>
<p>Macvlan 和 ipvlan 都是 Linux 系统的特性，其他系统不支持这个功能。</p>
<h2 id="prerequisites">Prerequisites</h2>
<p>可以用 <code>modinfo macvlan</code> 检查系统是否有安装 <code>macvlan</code> 模块，根据 <a href="https://docs.docker.com/network/network-tutorial-macvlan/#prerequisites">Docker 文档</a> 中描述的建议是使用 Linux 3.9 或 4.0 及更新的内核版本。</p>
<p>可以用以下指令检查系统是否支持 Macvlan（这里使用桥接模式）：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo ip link add macvlan0 link enp1s0 <span class="nb">type</span> macvlan mode bridge  <span class="c1"># 这里替换 enp1s0 为网卡接口名称</span>
</span></span><span class="line"><span class="cl">sudo ip address add 192.168.122.205/24 broadcast 192.168.122.255 dev macvlan0 <span class="c1"># 注意 IP 地址冲突</span>
</span></span></code></pre></div><p>之后可尝试使用其他处于同一个网络（CIDR）的设备 ping 这个 <code>192.168.122.205</code> IP 地址，能 Ping 通就说明你的防火墙没有屏蔽不同设备之间的二层数据转发。</p>
<h2 id="安装-k3s">安装 K3s</h2>
<p>根据 <a href="https://github.com/k8snetworkplumbingwg/multus-cni/blob/master/docs/quickstart.md">Multus 的 QuickStart 手册</a>，准备一个新版本的 Kubernetes 集群（这里用的是 <code>v1.27.8+k3s2</code>），K3s 默认的 CNI 插件使用的是 Flannel。</p>
<p>在国内的话需要先创建 <code>/etc/rancher/k3s/registries.yaml</code> 配置 Registry Mirror：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">mirrors</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">docker.io</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">endpoint</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="s2">&#34;https://docker.nju.edu.cn&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">ghcr.io</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">endpoint</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="s2">&#34;https://ghcr.nju.edu.cn&#34;</span><span class="w">
</span></span></span></code></pre></div><p>之后使用国内源一键安装 K3s：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="cp">#!/bin/bash
</span></span></span><span class="line"><span class="cl"><span class="cp"></span>
</span></span><span class="line"><span class="cl">curl -sfL https://rancher-mirror.oss-cn-beijing.aliyuncs.com/k3s/k3s-install.sh <span class="p">|</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>	<span class="nv">INSTALL_K3S_VERSION</span><span class="o">=</span>v1.27.8+k3s2 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>	<span class="nv">INSTALL_K3S_MIRROR</span><span class="o">=</span>cn <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>	sh -s - server <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>	--cluster-init <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>	--system-default-registry <span class="s2">&#34;docker.nju.edu.cn&#34;</span>
</span></span></code></pre></div><h2 id="安装-multus-cni">安装 Multus CNI</h2>
<p>接下来安装 Multus CNI 插件，下载 <code>multus-daemonset.yml</code> 配置，需要编辑 <code>kube-multus-ds</code> DaemonSet hostPath 的路径到 K3s 对应的路径上去。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">wget <span class="s1">&#39;https://raw.githubusercontent.com/k8snetworkplumbingwg/multus-cni/master/deployments/multus-daemonset.yml&#39;</span>
</span></span></code></pre></div><p>编辑 <code>kube-multus-ds</code> DaemonSet 的 <code>hostPath</code> 的配置为 K3s 的路径。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nn">...</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">volumes</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">cni</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">hostPath</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/var/lib/rancher/k3s/agent/etc/cni/net.d</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">cnibin</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">          </span><span class="nt">hostPath</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">            </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l">/var/lib/rancher/k3s/data/current/bin</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nn">...</span><span class="w">
</span></span></span></code></pre></div><p>还要编辑 <code>kube-multus-ds</code> DaemonSet 的 Container 配置，增添一条 command arg：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nn">...</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">      </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">kube-multus</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">ghcr.io/k8snetworkplumbingwg/multus-cni:snapshot</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">command</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&#34;/thin_entrypoint&#34;</span><span class="p">]</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="nt">args</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="s2">&#34;--multus-conf-file=auto&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="s2">&#34;--multus-autoconfig-dir=/host/etc/cni/net.d&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="s2">&#34;--cni-conf-dir=/host/etc/cni/net.d&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span><span class="c"># ADD THIS LINE:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">        </span>- <span class="s2">&#34;--multus-kubeconfig-file-host=/var/lib/rancher/k3s/agent/etc/cni/net.d/multus.d/multus.kubeconfig&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nn">...</span><span class="w">
</span></span></span></code></pre></div><p>之后 <code>kubectl apply</code> 上面的 Multus Daemonset 配置，等待 <code>kube-multus-ds</code> DaemonSet 跑起来后，可以看到 <code>/var/lib/rancher/k3s/data/current/bin</code> 目录下有新增 <code>multus</code> 可执行文件。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> sudo ls /var/lib/rancher/k3s/data/current/bin <span class="p">|</span> grep multus
</span></span><span class="line"><span class="cl"><span class="go">multus
</span></span></span></code></pre></div><h2 id="自定义-multus-cni-配置文件">自定义 Multus CNI 配置文件</h2>
<p>新建一个名为 <code>macvlan-conf</code> 的 <code>NetworkAttachmentDefinition</code> Custom Resource，自定义 multus 配置文件：</p>
<p>这里需要注意 <code>config</code> 中的 <code>master</code> 网卡接口要设置为物理机上对应的网卡接口名。</p>
<p>咱把 K3s Server 安装在了 QEMU 虚拟机中，虚拟机使用的是 libvirt 创建的默认网卡，CIDR 编址为 <code>192.168.122.0/24</code>，网关 <code>192.168.122.1</code>。
为了能在其他虚拟机 / 物理机上也能访问到虚拟机中使用了 macvlan 的 pod，multus macvlan 配置文件也使用 libvirt 网卡的 CIDR。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="s2">&#34;k8s.cni.cncf.io/v1&#34;</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">NetworkAttachmentDefinition</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">macvlan-conf</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">config</span><span class="p">:</span><span class="w"> </span><span class="s1">&#39;{
</span></span></span><span class="line"><span class="cl"><span class="s1">      &#34;cniVersion&#34;: &#34;0.3.1&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s1">      &#34;type&#34;: &#34;macvlan&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s1">      &#34;master&#34;: &#34;enp1s0&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s1">      &#34;mode&#34;: &#34;bridge&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s1">      &#34;ipam&#34;: {
</span></span></span><span class="line"><span class="cl"><span class="s1">        &#34;type&#34;: &#34;host-local&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s1">        &#34;subnet&#34;: &#34;192.168.122.0/24&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s1">        &#34;rangeStart&#34;: &#34;192.168.122.200&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s1">        &#34;rangeEnd&#34;: &#34;192.168.122.210&#34;,
</span></span></span><span class="line"><span class="cl"><span class="s1">        &#34;routes&#34;: [
</span></span></span><span class="line"><span class="cl"><span class="s1">          { &#34;dst&#34;: &#34;0.0.0.0/0&#34; }
</span></span></span><span class="line"><span class="cl"><span class="s1">        ],
</span></span></span><span class="line"><span class="cl"><span class="s1">        &#34;gateway&#34;: &#34;192.168.122.1&#34;
</span></span></span><span class="line"><span class="cl"><span class="s1">      }
</span></span></span><span class="line"><span class="cl"><span class="s1">    }&#39;</span><span class="w">
</span></span></span></code></pre></div><div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> kubectl apply -f macvlan-conf.yaml
</span></span><span class="line"><span class="cl"><span class="gp">$</span> kubectl get net-attach-def
</span></span><span class="line"><span class="cl"><span class="go">NAME           AGE
</span></span></span><span class="line"><span class="cl"><span class="go">macvlan-conf   59s
</span></span></span></code></pre></div><h2 id="创建-macvlan-pod">创建 Macvlan Pod</h2>
<p>K3s 将安装包体积做了精简移除了 <code>macvlan</code> CNI 插件，所以创建 Pod 之前需要手动下载 <code>macvlan</code> CNI 插件放到 K3s 的 data bin 目录。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> mkdir -p cni-plugin <span class="o">&amp;&amp;</span> <span class="nb">cd</span> cni-plugin
</span></span><span class="line"><span class="cl"><span class="gp">$</span> wget https://github.com/containernetworking/plugins/releases/download/v1.4.0/cni-plugins-linux-amd64-v1.4.0.tgz
</span></span><span class="line"><span class="cl"><span class="gp">$</span> tar -zxvf cni-plugins-linux-amd64-v1.4.0.tgz
</span></span><span class="line"><span class="cl"><span class="gp">$</span> sudo cp ./macvlan /var/lib/rancher/k3s/data/current/bin/
</span></span></code></pre></div><p>之后创建 Pod，使用 Annotation 指定网络的配置文件，并让 Pod 被 Multus CNI 识别。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-yaml" data-lang="yaml"><span class="line"><span class="cl"><span class="nt">apiVersion</span><span class="p">:</span><span class="w"> </span><span class="l">v1</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">kind</span><span class="p">:</span><span class="w"> </span><span class="l">Pod</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">metadata</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">nginx-macvlan</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">annotations</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">k8s.v1.cni.cncf.io/networks</span><span class="p">:</span><span class="w"> </span><span class="l">macvlan-conf</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w"></span><span class="nt">spec</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span><span class="nt">containers</span><span class="p">:</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">  </span>- <span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w">
</span></span></span><span class="line"><span class="cl"><span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l">nginx</span><span class="w">
</span></span></span></code></pre></div><p>如果一切顺利的话，<code>kubectl describe pod nginx-macvlan</code> 能看到以下的 Events：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">Events:
</span></span><span class="line"><span class="cl">  Type    Reason          Age   From               Message
</span></span><span class="line"><span class="cl">  ----    ------          ----  ----               -------
</span></span><span class="line"><span class="cl">  Normal  Scheduled       2s    default-scheduler  Successfully assigned default/nginx-macvlan to archlinux-k3s-1
</span></span><span class="line"><span class="cl">  Normal  AddedInterface  2s    multus             Add eth0 [10.42.0.26/24] from cbr0
</span></span><span class="line"><span class="cl">  Normal  AddedInterface  2s    multus             Add net1 [192.168.122.200/24] from default/macvlan-conf
</span></span></code></pre></div><p>因为 K3s 服务器跑在了 QEMU KVM 虚拟机里面，libvirt 默认网卡 CIDR 是 <code>192.168.122.0/24</code>。所以咱在物理机上访问虚拟机内的 Macvlan Pod IP <code>192.168.122.200</code>，是能正常访问的。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-console" data-lang="console"><span class="line"><span class="cl"><span class="gp">$</span> curl 192.168.122.200
</span></span><span class="line"><span class="cl"><span class="go">&lt;!DOCTYPE html&gt;
</span></span></span><span class="line"><span class="cl"><span class="go">&lt;html&gt;
</span></span></span><span class="line"><span class="cl"><span class="go">&lt;head&gt;
</span></span></span><span class="line"><span class="cl"><span class="go">&lt;title&gt;Welcome to nginx!&lt;/title&gt;
</span></span></span><span class="line"><span class="cl"><span class="go">...
</span></span></span></code></pre></div><p>然后因为 Macvlan 的子接口 (sub interface) 无法与父接口 (parent interface) 直接访问，所以在节点的主机上访问运行在这个节点内的 macvlan pod 是访问不通的，也就是说无法通过节点主机的接口访问到 macvlan pod 的子接口，除非使用 ipvlan，可以参考以下这几篇讨论：</p>
<ul>
<li><a href="https://stackoverflow.com/questions/69316893/single-node-microk8s-multus-master-interface-cannot-be-reached">Single node Microk8s multus master interface cannot be reached</a></li>
<li><a href="https://forums.docker.com/t/host-and-containers-cannot-communicate-macvlan/112968">Host and Containers cannot communicate - MACVLAN</a></li>
</ul>]]></content:encoded>
    </item>
    
    <item>
      <title>一些 Arch Linux 的常用组件整理</title>
      <link>https://blog.starry-s.moe/posts/2024/archlinux-utils/</link>
      <pubDate>Tue, 30 Jan 2024 18:44:07 +0800</pubDate>
      
      <guid>https://blog.starry-s.moe/posts/2024/archlinux-utils/</guid>
      <description>&lt;p&gt;用这么久 Arch 了，但是却很少写 Arch 相关的博客……&lt;/p&gt;
&lt;p&gt;最近常需要在虚拟机上装 Arch，所以把常用工具及配置整理在这儿，省得每次 &lt;code&gt;pacstrap&lt;/code&gt; 时都要想半天咱需要装什么……&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>用这么久 Arch 了，但是却很少写 Arch 相关的博客……</p>
<p>最近常需要在虚拟机上装 Arch，所以把常用工具及配置整理在这儿，省得每次 <code>pacstrap</code> 时都要想半天咱需要装什么……</p>
<meting-js server="netease" type="song" id="2104716079" theme="#233333"></meting-js>
<hr>
<h2 id="装系统">装系统</h2>
<p>Arch Wiki 的 Installation Guide 在使用 <code>pacstrap</code> 装系统时只写了最基础的软件包 <code>base</code>, <code>linux</code> 和 <code>linux-firmware</code>，可以在这一步补充亿些常用的软件。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">pacstrap -K /mnt base linux linux-firmware <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    base-devel gcc grub amd-ucode  <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    zsh zsh-syntax-highlighting zsh-autosuggestions <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    vim neovim git openbsd-netcat <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    sudo man-db htop wget <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    neofetch
</span></span></code></pre></div><p>进 chroot 后编辑 <code>/etc/pacman.conf</code>，添加以下配置，启用 Arch Linux CN。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl"># /etc/pacman.conf
</span></span><span class="line"><span class="cl">[archlinuxcn]
</span></span><span class="line"><span class="cl"># Server = https://repo.archlinuxcn.org/$arch
</span></span><span class="line"><span class="cl">Server = https://mirrors.bfsu.edu.cn/archlinuxcn/$arch
</span></span></code></pre></div><p>之后安装 <code>yay</code>:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo pacman -Syy <span class="o">&amp;&amp;</span> sudo pacman -S archlinuxcn-keyring yay
</span></span></code></pre></div><p>如果电脑上安装了其他系统的话，需要额外安装 <code>os-prober</code>，让 GRUB 在生成配置文件时搜索安装了其他系统的磁盘。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo pacman -S os-prober
</span></span></code></pre></div><p>如果是为 QEMU KVM 虚拟机装系统的话，在执行 <code>grub-install</code> 配置 UEFI 启动引导时记得加一个 <code>--removable</code> 参数。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo grub-install --target<span class="o">=</span>x86_64-efi --efi-directory<span class="o">=</span>/boot --bootloader-id<span class="o">=</span>GRUB --removable
</span></span><span class="line"><span class="cl">sudo grub-mkconfig -o /boot/grub.cfg
</span></span></code></pre></div><p>如果不装其他网络工具，只使用 <code>systemd-networkd</code> 的话，需要创建一份默认的配置文件使用 DHCP，否则连不上网。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl"># /etc/systemd/network/10-default.network
</span></span><span class="line"><span class="cl">[Match]
</span></span><span class="line"><span class="cl">Name=enp*
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[Network]
</span></span><span class="line"><span class="cl">DHCP=yes
</span></span></code></pre></div><p>如果需要配置静态网络地址：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl"># /etc/systemd/network/10-static.network
</span></span><span class="line"><span class="cl">[Match]
</span></span><span class="line"><span class="cl">Name=eth0
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[Network]
</span></span><span class="line"><span class="cl">Address=10.128.0.100/16
</span></span><span class="line"><span class="cl">Gateway=10.128.0.1
</span></span><span class="line"><span class="cl">DNS=10.128.0.1
</span></span></code></pre></div><p>并启用 <code>systemd-networkd</code> Systemd Service：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">sudo systemctl enable systemd-networkd
</span></span></code></pre></div><p>基本上到这里就可以愉快的 <code>reboot</code> 了，一个精简的系统所需要的软件就基本装好了。</p>
<h2 id="常用命令行工具">常用命令行工具</h2>
<p>如果只作为服务器 / 不包含图形的虚拟机使用的话，装这些咱常用软件，这部分因人而异，仅供参考。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo pacman -S go <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    kubectl helm <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    docker docker-buildx <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    privoxy <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    proxychains <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    wireguard-tools <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    axel aria2 <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    ffmpeg <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    jq go-yq <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    jdk8-openjdk <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    lm_sensors <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    net-tools traceroute <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    nodejs npm <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    python3 python-pip <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    btrfs-progs <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    <span class="nb">bind</span> <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    ethtool <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    bc <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    age
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># golangci-lint</span>
</span></span><span class="line"><span class="cl">yay -S golangci-lint-bin <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    krew-bin
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 装完 Docker 后把普通用户添加到 docker group 中</span>
</span></span><span class="line"><span class="cl">sudo usermod -aG docker <span class="nv">$USER</span>
</span></span></code></pre></div><p>创建 Docker Daemon 的配置文件 <code>/etc/docker/daemon.json</code>，设定国内的 Mirror，这里用的是南京大学的 Docker Mirror：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-json" data-lang="json"><span class="line"><span class="cl"><span class="p">{</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&#34;insecure-registries&#34;</span> <span class="p">:</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;127.0.0.1:5000&#34;</span>
</span></span><span class="line"><span class="cl">  <span class="p">],</span>
</span></span><span class="line"><span class="cl">  <span class="nt">&#34;registry-mirrors&#34;</span><span class="p">:</span> <span class="p">[</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;https://docker.nju.edu.cn/&#34;</span>
</span></span><span class="line"><span class="cl">  <span class="p">]</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p>如果需要跑虚拟机，需要装 QEMU 和 <code>libvirt</code> 相关的组件（咱用 <code>virsh</code> 管理虚拟机，不手搓 qemu 指令）：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo pacman -S qemu-full libvirt
</span></span></code></pre></div><h3 id="k3s--rke2-server">K3s / RKE2 Server</h3>
<p>在 Arch Linux 上安装了 K3s 或 RKE2，关机时会卡在 <code>a stop is running for libcontainer containerd...</code> 一分多钟……</p>
<p>参考 <a href="https://github.com/k3s-io/k3s/issues/2400#issuecomment-1312621468">这个 Issue</a>，创建一个 <code>/etc/systemd/system/shutdown-k3s.service</code> Systemd 文件。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl">[Unit]
</span></span><span class="line"><span class="cl">Description=Kill containerd-shims on shutdown
</span></span><span class="line"><span class="cl">DefaultDependencies=false
</span></span><span class="line"><span class="cl">Before=shutdown.target umount.target
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[Service]
</span></span><span class="line"><span class="cl">ExecStart=/usr/local/bin/k3s-killall.sh
</span></span><span class="line"><span class="cl">Type=oneshot
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">[Install]
</span></span><span class="line"><span class="cl">WantedBy=shutdown.target
</span></span></code></pre></div><p>之后启用 <code>shutdown-k3s.service</code>，在关机时 Kill 掉 K3s。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo systemctl daemon-reload
</span></span><span class="line"><span class="cl">sudo systemctl <span class="nb">enable</span> shutdown-k3s.service
</span></span></code></pre></div><h3 id="wireguard-client">WireGuard Client</h3>
<p>如果 Arch Linux 还配置了 WireGuard 客户端，而这台 Arch Linux Server 被放在了家里，只能通过有公网 IP 的 WireGuard 服务器连接进去，这时尽管设置了 WireGuard 的 <code>persistent keepalive</code>，但在运营商更换了你家的公网 IP 后，还是会碰到无法自动连接回去的情况，这时可以用咱的 <a href="https://github.com/STARRY-S/wireguard-keepalive">这个简单粗暴的脚本</a>，在 WireGuard 断连一段时间后，自动重启接口。</p>
<h2 id="图形界面">图形界面</h2>
<p>显卡驱动：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># AMD</span>
</span></span><span class="line"><span class="cl">sudo pacman -S xf86-video-amdgpu
</span></span><span class="line"><span class="cl"><span class="c1"># NVIDIA</span>
</span></span><span class="line"><span class="cl">sudo pacman -S nvidia
</span></span></code></pre></div><p>X11/Wayland 这些相关组件会随着桌面环境一起安装，所以只需要装桌面环境即可，<span class="spoiler" >这里就不需要你额外装 X 了</span>。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl"><span class="c1"># 咱用 GNOME</span>
</span></span><span class="line"><span class="cl">sudo pacman -S gnome
</span></span><span class="line"><span class="cl"><span class="c1"># 通常不直接装 gnome-extra，而是从里面选咱需要的</span>
</span></span><span class="line"><span class="cl">sudo pacman -S gnome-tweaks
</span></span><span class="line"><span class="cl"><span class="c1"># GNOME 系统使用的 NetworkManager 需要额外安装并手动启用，否则无法联网</span>
</span></span><span class="line"><span class="cl">sudo pacman -S networkmanager
</span></span><span class="line"><span class="cl">sudo systemctl <span class="nb">enable</span> --now NetworkManager
</span></span></code></pre></div><h2 id="常用的-gui-软件">常用的 GUI 软件</h2>
<p>装好图形界面并顺利跑起来之后，就可以装常用的桌面软件了，下面这些是部分可能用到的软件，这些因人而异，仅供参考。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo pacman -S vlc <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    virt-manager <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    ttf-monaco <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    noto-fonts noto-fonts-cjk noto-fonts-emoji ttf-dejavu <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    ibus ibus-rime <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    firefox <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    emacs
</span></span></code></pre></div><p>在 AUR 中安装的软件：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">yay -S google-chrome <span class="se">\
</span></span></span><span class="line"><span class="cl"><span class="se"></span>    visual-studio-code-bin
</span></span></code></pre></div><h3 id="启用-multilib">启用 Multilib</h3>
<p>启用 Multilib 以安装那些 32 位的软件，例如 Steam。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-fallback" data-lang="fallback"><span class="line"><span class="cl"># /etc/pacman.conf
</span></span><span class="line"><span class="cl">[multilib]
</span></span><span class="line"><span class="cl">Include = /etc/pacman.d/mirrorlist
</span></span></code></pre></div><p>之后安装 Steam。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo pacman -S steam
</span></span></code></pre></div><p>如果需要加速 Steam 游戏，可以安装 <a href="https://aur.archlinux.org/packages/uuplugin-bin">uuplugin-bin</a>，把电脑伪装成 Steam Deck，酱紫路由器有 UU 加速器插件的话就能给 Steam 加速。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">yay -S uuplugin-bin
</span></span></code></pre></div><p>如果要运行 Windows 游戏，还要安装 Proton。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">yay -S proton
</span></span></code></pre></div><h3 id="音乐">音乐</h3>
<p><code>netease-cloud-music</code> 这个包已经很久没更新了，现在很多功能用不了，除了这个还有一些基于 GTK4 写的网易云音乐客户端也能用。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">yay -S netease-cloud-music <span class="c1"># 网易云音乐</span>
</span></span><span class="line"><span class="cl">yay -S cider-bin           <span class="c1"># Apple Music</span>
</span></span></code></pre></div><h3 id="流程图">流程图</h3>
<p>Draw.io 这个工具画流程图很好用，而且支持 Linux，可以直接从 Arch Linux CN 安装。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sudo pacman -S drawio-desktop-bin
</span></span></code></pre></div><hr>
<p>未完待续，如果还想到了别的再补充到这儿。</p>]]></content:encoded>
    </item>
    
    <item>
      <title>Hello 2024</title>
      <link>https://blog.starry-s.moe/posts/2024/hello-2024/</link>
      <pubDate>Thu, 18 Jan 2024 23:12:28 +0800</pubDate>
      
      <guid>https://blog.starry-s.moe/posts/2024/hello-2024/</guid>
      <description>&lt;p&gt;这里没有年终总结。&lt;/p&gt;</description>
      <content:encoded><![CDATA[<p>这里没有年终总结。</p>
<meting-js server="netease" type="song" id="2101842506" theme="#233333"></meting-js>
<br/>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-sh" data-lang="sh"><span class="line"><span class="cl">sed <span class="s1">&#39;s/2023/2024/g&#39;</span>
</span></span></code></pre></div><p>没什么头绪，不知道该从什么地方说起。</p>
<h2 id="旅行">旅行</h2>
<p>2023 年咱去了很多很多的地方，去了成都、重庆、上海、长春、本溪、哈尔滨、长白山（是 2024 年初去的但依旧放在今年的总结里吧）。</p>
<p>现在回想一下，在成都和重庆去了他们那边当地的漫展和一些专门为游客准备的景点（世界线展子好大）。今年一共去了三次上海，第一次是去的 Bilibili World 和 Bilibili Macro Link。第二次是去的 KubeCon。第三次是去看梶浦由记的 Live，顺便去了一趟野生动物园。（实际上差点就去了四次，但是上海梦兽和 KubeCon 时间撞车了，门票没买到所以没去成）。在吉林参加了两次兽聚，分别是长春的疯狂一夜小聚和长白山附近的白兽渊。长白山景区因为下雪封闭了所以没去成（嗯，都是某位雪神的锅，哼），滑雪时间来不及了也没滑上。年底去了尔滨冰雪大世界，体验了一把在室外零下二十多度的地方排队四个小时的滋味……</p>
<h2 id="生活">生活</h2>
<p>工作和生活方面与 22 年咱回到辽宁后没什么变化，咱依旧是居住在沈阳这座城市，今年是咱大学毕业后，在沈阳这个城市定居的第一年。不过幸好咱大学也是在沈阳念的，所以没有遇到过多的水土不服和气候、环境不适应的情况，也就是年初的时候经历过许多次的生病发烧、各种感冒（几乎不到一个月一次的那种），应该是因为租的房子的原因吧，空间狭窄、不通风、很闷，沈阳的冬天又那么的干冷，真的很容易生病。不过从校园生活转变为在校园外的感觉很不一样，咱之前可没和这么多的东北人打过交道，虽然第一反应觉得东北话挺逗挺有意思的，但时间久了实际上东北话有一种语气蛮横，充满脏话，很直白的那种，给人很不舒服的感觉。尤其是碰到过很多黑心出租车，欺负外地人，嗯，出租车司机只是咱举的一个栗子，就是总能在很多细节的地方找出曾经的老工业和军阀的气息。而沈阳排斥外地人的方式也很有特点，大多数人的思维方式也蛮与众不同的，总之就是碰到那种能和你唠一道的出租车司机，跟你骂骂咧咧抱怨这抱怨那的，你就迎合他说啊对对对，啊是是是，哄他心情开心就得了，咱一个人生活在这座城市，打车可不敢招惹这样的司机，也犯不上和这种人闹别扭是吧。</p>
<p>咱没有什么地域黑的意思，至少咱还是喜欢沈阳这座城市的，在别的城市也能碰到不同的人和事，强者从不抱怨环境，但咱不是强者，不配抱怨环境，也决定不了自己所在的环境，不要问咱为什么要回沈阳，也不要羡慕那些自己没有而别人有的东西。咱只是觉得这座城市似乎出于什么原因，很多地方都和外界隔绝了一样，有种大范围的信息差不对等的感觉。经常能听到有人说 “东北谁爱回谁回，我反正不回” 这样的言论，但至少现在是有许多人在努力改善这种情况（当然也有许多人在努力防止这种情况被改善就是了）。有机会的话多去沈阳的市博物馆、陵寝和故宫那附近逛逛，了解点历史还是有帮助的，起码能帮助外地人熟悉这座城市，而不是单纯的通过表面现象去做结论。</p>
<p>咳，说多了，至于为什么今年去了那么多城市一个主要的原因就是想尽可能的改善咱的社恐，咱很纳闷为什么在别的城市就能过的好好的偏偏回到东北就变成了这个样子。其实咱在之前上学的时候，就一直想的是以后坚决不留在东北，以后一定要去老师和亲戚朋友口中所说的南方大城市。当时咱就是很难适应东北的种种事情，咱和沈阳本地人几乎没有过什么交流，咱只记得那时候，路边的小商铺一直在用大声的音箱放着土味音乐和吆喝声，总能看到 “精神小伙” 和某手短视频、土味段子的这种低俗没营养的视频（我不看但身边总有同学在外放这些）。至于同学举行的聚会、社团活动什么的，咱在大一转专业之前试着参加过几次但因为很不合群，闹得十分不愉快而最终不再参加这样的活动了。工作之后，在意识到咱回到东北了，突然意识到咱根本就没办法和本地人正常交流这件事，从而变成了十分严重的社恐，就像一个丢了 Context 的 Go Routine 一样，咱就这么成为了一个大号的社会不适应者，等着被这个社会淘汰掉。其实咱有想过要不要去看心理医生之类的但最终还是不想去医院，没有什么理由就是觉得咱有自己的方式能解决这些问题，如果治不好的话就算了。逼着这种病态的社恐人去参加些什么社交活动，只会加重这种情况。</p>
<p>出于爱好，咱经常去沈阳本地的漫展，也就是在年初的漫展上看到了一群大福瑞从而被拖下水入坑了福瑞控。讲真在其他城市的漫展很少能看到这么多的大福瑞，咱也是从这时候开始尝试和他们加好友聊天，还试着参加一些线下的社团活动（但是效果并不好，所以咱后来又把这些社团退掉了，到现在咱还是很谨慎几乎不加入社团什么的）。咱在入坑福瑞之后买了一台入门残幅相机，尝试给他们拍照返图，顺便认识了一些新的朋友。因为福瑞这个圈子，额，不太好和圈外的人解释，所以很长一段时间以来咱从来没和圈外的人提到过咱也是福瑞这个事。也就到了年底咱在别的装师那里捡了一个掉落头之后，才开始大量的向咱的社交帐号上发福瑞相关的东西，顺便去了长白山的兽聚，和一群大佬们合影、交换物料、试着参加一些活动什么的，不过咱依旧是和身边任何人保持着很大的距离感……</p>
<p>咱没有刻意隐瞒咱是福瑞这些相关的东西，也并没有想背着别人搞一些坏事什么的。其实就算被身边的人发现了也没什么大不了的，只取决于圈外的人对福瑞的看法了，所以避免不必要的争吵，大多数时候咱还是不想让他们知道而已。所以请避免当面问我不礼貌的问题，不要开黄腔，不要讨论性别，不要讨论性取向，可以开玩笑但不要过分。崽子是崽子，内胆是内胆，不要把崽子的事情上升到内胆，如果不喜欢看可以不看，不要把崽子的形象和内胆进行绑定，不要盗图盗设定，不要拍打兽装头部，这些都是基本常识。</p>
<p>但是，咱真的很想认识更多的朋友，虽然咱反感社交，但参加完这些活动后真的能开心好长好长一段时间。咱真的不再希望自己一个人孤零零的去漫展了，一个人去兽聚没人拼酒店票真的很没意思，很多旅游景点明摆着就是给多人准备的，一个人根本就玩不了（但是不要问我为什么没有邀请你一起去漫展/兽聚这些活动，只是单纯的认为不合适，我没有准备好，这样子会很尴尬的）。</p>
<p>还有就是，网络上的社交软件能展示的东西太少了，这个窗口只能暴露出极少数的文字和图片等信息，但人们往往把网络上展示出来的部分信息当作成了这个人的全部，这很容易就会引起很大很大的误会，这也是咱为什么逐渐的不想在网络上发更多的消息了，尤其是咱的微信加了各种各样的好友，于是就不想再发只适合某类好友看的朋友圈了。聊天软件上发的几行文字是不带语速、情感、环境信息的，如果可以的话咱更希望是通过面对面的聊天去熟悉一个人，而不是通过他在社交平台上发的一些文字、聊天软件上发的表现不出来完整情感的几句话。至于那些曾经由种种原因已经产生的误会，咱也不打算去和别人解释了，有时候就保持着这些误会也挺好的，到能解开的时候自然就解开了，解不开就算了。</p>
<p>但是咱还是很怀念那些曾经因为种种原因导致的已经不联系了的朋友们，唉。</p>
<h2 id="工作">工作</h2>
<p>工作一年多了，依旧在学很多新的知识。比较值得一提的是咱今年去了上海的 KubeCon，除了在公司的展台那里帮忙收拾东西，空余时间还可以去楼上的各个会场听大佬们的演讲。说实话除了上海应该不会再有别的城市能举行这种大规模国际化的、带有开源社区的大型活动了。貌似有很多公司是奔着商业主题相关的演讲去的，但咱个人层面则是更倾向于去看一些开源技术的演讲，咱属于是刚接触这个领域没多久，属于是什么都想听，但时间紧只能从日程表中选出某几个演讲去听的那种。尽管咱听不懂（听不懂英语 + 听不懂技术内容）但多少能收获到那些大佬们的一些思路、思维方式和写开源项目的风格、感受一下技术氛围之类的，至少咱后面的程序开发思路可以借鉴一部分，这些往往是商业的演讲容易遗漏掉的东西。听这些大佬们的演讲有一种在大学上课的感觉，只是听一遍的话肯定是记不住老师讲的什么内容的，而咱根本就没打算要把所有演讲的内容全记脑子里，咱就是感觉这种氛围是真的和大学的课堂很像很像。因为咱这个年龄就和个小孩子似的，去这种 Conference 要不是戴着公司的胸牌估计就直接被保安拦外面了……当时保安还怀疑我的胸牌是不是复印假的每次都是反复检查好久才放我进去。印象比较深的就是在发物料时，有好多在上海的大学生过来领，然后他们的胸牌上的公司名称写的要么是某某大学什么的，要么就是胡乱起的名字，就挺有意思的…… 嗯咱今年一共领了两种不同的英特尔袋子，一个是在 B 站的 BW 上领的（听说这个袋子在当时虹桥那边暴雨发水时保住了好多 Coser 的衣服），另一个是在 KubeCon 上领的，英特尔他真的好喜欢发袋子。去完 KubeCon 后一直想找时间去学 Rust 和 Linux Kernel 的 eBPF 相关知识来着，但这个貌似要推到 2024 年再去学了。公司对新人真的太好了，能有这样的机会去上海的 KubeCon 真的开心死了。</p>
<p>从 KubeCon 回来后咱把咱自己曾经写的一个开源程序给重构了一遍，基本上就是咱的上一篇博客里讲的那些内容。本来想单独开一篇博客介绍这个程序的但最近真的真的太忙了没时间了所以就没写（实际博客内容都写一半了但既然写年终总结了就压缩一下内容放在这里吧）。因为这个程序主要还是应用在云原生相关的场景的，所以咱也仿照着 Rancher 官网、K3s 官网这些去重写了一下咱这个程序的文档网站（官网）。咱还把咱的程序按照咱的思维去重构了一遍，比如咱个人的观点认为，要编写一个清真的开源软件，除非万不得已，不要调用任何其他第三方的二进制文件（当然这里说的二进制文件是指一个可执行文件，不是动态库，还有除非你的程序就是设计为一个 Wrapper，否则为了长远考虑，不要为了实现某个功能而调用某个第三方的可执行文件），而是通过已有的 API 和 Library 通过代码去实现这些功能，再大一点的项目还会手搓轮子，不引入第三方库。然后咱还从用户侧的角度考虑了一下把那些用户可能遇到的使用体验不友好的地方全都重构了一遍（其实之前的用户体验也蛮好的，只是有那么几个可优化的地方……）。咱今年可是花了很大的精力去重新设计这个程序的代码，毕竟写一个 Demo 程序和真正的把它拿去给用户去用是两码事。起初这个程序是咱刚初学 Go 语言时，一边学 Go 的基本语法一边去糊这个程序的功能，现在一想当时咱写的程序真的很乱，设计的很难看（但起码能用），当时咱对于怎么处理 Go 的并发、怎么用 Context、接口到底是怎么用的这些一无所知，而且书本只能教给你接口、Context、Signal 是什么，但他们不会告诉你怎么在大型项目中优雅的使用它。重构完了这个项目之后尽管程序设计上依旧存在缺陷，但起码他比以前好了很多了，咱这回用了 Go 的 Channel 和 Context 更好的处理了异常和错误信息，还相对正确的使用了 Go 的 Interface 接口去设计。尽管重构后的程序功能和之前貌似没什么区别，对用户来讲改动不是很大（也就少了一些依赖，压缩包格式变了，日志的内容变了），但从代码这边基本上是完全重写了（<span class="spoiler" >修复了一些 bug 并引入了一些新的 bug</span>）。咱可不希望只为了实现功能而写出丑陋的代码，因为这是开源的软件，如果有别的社区的人想做贡献时，没人愿意在丑陋的代码上耗费时间。</p>
<p>所以说了这么多，咱把咱写的程序网址贴在这里，感兴趣的话就去看看：<a href="https://hangar.cnrancher.com">https://hangar.cnrancher.com</a></p>
<h2 id="游戏">游戏</h2>
<p>今年并没打什么游戏，玩了一阵子的守望先锋，但这游戏越来越没意思了逐渐不怎么玩了，Minecraft 也没怎么玩，就偶尔空闲时间进去逛逛。同学有时候还会喊我去打一些游戏，但大多数时间咱都推掉了。</p>
<p>想玩的游戏还有很多，一直想找机会二刷一遍月姬和魔法使之夜，魔夜重置版的支线咱也还没打完，还蛮期待过一阵子即将新出的月姬官方汉化和最终幻想 7 重置版的续作的。</p>
<h2 id="其他">其他</h2>
<p>2023 年实际上对咱来说是一个很糟糕的一年，我很烦那些不切实际的羡慕，我很反感那些对自己现状不满而总是羡慕别人的人。很多时候咱把咱好的一面展现出来而把不好的事情埋在心里，不想让别人担心，就算是生病或者心情不好到了极点咱也会发点和这些不相关的朋友圈和消息之类的，我不想向别人讲自己的烦恼和困扰，但这会给人一种 “他过得比我好，我好羡慕他” 的感觉。很多时候是咱靠着仅存的一点兴趣和爱好一个人在硬撑着，但是那种有些东西自己没有而别人有就去说风凉话的真的很恶心。很多事都不是凭空偶然发生的，特别的能力会招惹来特别的能力。嗯，不知道自己还能撑多久，也不知道自己以后会去哪里，总之就是挺喜欢橙子老师说的，“我们并不是根据背负的罪来选择道路，而是先选择道路再背负起自己的罪孽”，“所谓的 ‘逃’ 有两种，漫无目的的逃以及带有目的的逃。一般将前者称为 ‘漂浮’，后者称为 ‘飞行’”。不知道咱自己还能飞多久，也不知道自己是在故意挥动翅膀，装出自己好像在飞行的样子，实际已经坠落了呢。</p>]]></content:encoded>
    </item>
    
  </channel>
</rss>
